{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Oq1gytVV7D"
      },
      "source": [
        "# Low-Dimensional GAN\n",
        "## Exercise M5, Visual Recognition, Master in Computer Vision\n",
        "### Diego Porres, dporres@cvc.uab.es\n",
        "Postdoctoral Researcher, ADAS Research Group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7wzQ1DsYKEi"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "[Generative Adversarial Networks](https://en.wikipedia.org/wiki/Generative_adversarial_network) or GANs for short are, without a doubt, one of the most widely known algorithms in Machine Learning nowadays. As you have seen in the lectures, GANs are a different type of models than the ones that one typically encounters. Being from the branch of [Unsupervised Learning](https://sites.google.com/view/berkeley-cs294-158-sp20/home), they are specifically tasked with learning an *implicit* representation of the training dataset distribution $p_\\text{data}$. While a subfield of [generative modeling](https://en.wikipedia.org/wiki/Generative_model), they are not the only widely-used models from this field.\n",
        "\n",
        "![Generative Models](https://user-images.githubusercontent.com/24496178/75723388-7ee94a00-5cdc-11ea-8132-9aa1b03d042b.png \"Generative Models\")\n",
        "[Image Source](https://www.manning.com/books/gans-in-action)\n",
        "\n",
        "GANs are a hot topic nowadays, especially since [Yann LeCun](http://yann.lecun.com/) said that GANs where the \"most interesting idea in the last 10 years in ML\" back in [2016](https://qr.ae/TQiKBM). A bold statement, but not a totally incorrect one. We can easily see how this is reflected within the research community when looking at the plot of the cumulative number of named GAN papers by month ever since:\n",
        "\n",
        "![GANs are a hot topic](https://raw.githubusercontent.com/hindupuravinash/the-gan-zoo/master/cumulative_gans.jpg \"GANs are a hot topic\")\n",
        "[Image Source](https://github.com/hindupuravinash/the-gan-zoo)\n",
        "\n",
        "Perhaps what has truly astonished many is the ability to generate, in a completely unsupervised way, new images that should belong to a specific dataset distribution, such as human faces. Indeed, it seems like we have simply bypassed the [uncanny valley](https://en.wikipedia.org/wiki/Uncanny_valley) altogether, reaching quality levels (as we will see a glimpse shortly) that were never even dreamed of before.\n",
        "\n",
        "While GANs aren't a new idea per se([O. Niemitalo's 2010-02-24 blog post](https://web.archive.org/web/20120312111546/http://yehar.com:80/blog/?p=167) and [J. Schmidhuber's 1992 paper](ftp://ftp.idsia.ch/pub/juergen/factorial.pdf) come to mind; read [this discussion](https://stats.stackexchange.com/questions/251460/were-generative-adversarial-networks-introduced-by-j%C3%BCrgen-schmidhuber) to better understand the history), they have become mainstream ever since [Goodfellow's paper in 2014](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf). It is the latter paper that will guide this notebook, so I hope you have the time to read it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzG3Bq-k5nhs"
      },
      "source": [
        "## But first, some of my favorite applications\n",
        "\n",
        "GANs have been applied to many different fields apart from Computer Science, such as [art](http://www.aiartonline.com/), [image coloring and restoration](https://github.com/jantic/DeOldify), [image super-resolution](https://github.com/tensorlayer/srgan), and more. You have seen some examples in the class lectures, so I will proceed only with some of my favorites:\n",
        "\n",
        "[Artbreeder](https://artbreeder.com/) is an excellent case for presenting the intersection between human creativity and technology. Using [BigGAN](https://arxiv.org/abs/1809.11096), [StyleGAN](https://arxiv.org/abs/1812.04948) and [StyleGAN2](https://arxiv.org/abs/1912.04958), it lets its users mix different images in order to get the trained network do the heavy lifting of generating the image and the user will have the task of selecting the ones that are closest to what they wish to accomplish. Even [full body characters](https://twitter.com/artbreeder/status/1210249276196040704?lang=en) can now be generated in the platform, as we can see in the following image.\n",
        "\n",
        "![Artbreeder characters](https://user-images.githubusercontent.com/24496178/73453756-fbe77380-436c-11ea-929a-f17e7273a95c.png \"Artbreeder characters\")\n",
        "\n",
        "Unsupervised generation of faces has seen some serious leaps in progress in the last couple of years. Looking at the image below, it is truly remarkable what has been achieved, even more when we consider the fact that this sample of faces do not include the latest development, the [StyleGAN2](https://arxiv.org/abs/1912.04958), where the authors have corrected some issues with the previous model SOTA, the [StyleGAN](https://github.com/NVlabs/stylegan) (rightmost face in the image below).\n",
        "\n",
        "![4.5 year GAN progress](https://user-images.githubusercontent.com/24496178/75048968-add81280-54c9-11ea-9ea7-39dba36e7f52.png \"4.5 year GAN progress\")[Image Source](https://www.iangoodfellow.com/slides/)\n",
        "\n",
        "Perhaps one of the most notorious use of this type of model is the website [thispersondoesnotexist.com](https://www.thispersondoesnotexist.com/) and my favorite variants, [thisvesseldoesnotexist.com](https://thisvesseldoesnotexist.com/) and [thiswaifudoesnotexist.com](https://www.thiswaifudoesnotexist.net/) (all of which either use StyleGAN or StyleGAN2). Each time you refresh the former, you will obtain a new image of a face/vessel/waifu that, as its name implies, does not exist. While certainly not as *creative* as Artbreeder, many of the generated samples are fun to observe, in a way making you an expert in detecting these fake versions. [Aydao](https://aydao.ai/), [Gwern](https://www.gwern.net) and [NearCyan](https://nearcyan.com/) have been hard at work and now have extended the capabilities of StyleGAN2 far beyond what has been previously possible [thisanimedoesnotexist.ai](https://thisanimedoesnotexist.ai/). For details on how they expanded StyleGAN2's capabilities, read [this blog post](https://www.gwern.net/Faces#extended-stylegan2-danbooru2019-aydao). Nothing quite like anime that will inspire reasearches into pushing the limits of SOTA algorithms.\n",
        "\n",
        "For a more extensive list of similar websites like these ones, as well as other generative models, check out [thisrepositorydoesnotexist](https://github.com/paubric/thisrepositorydoesnotexist).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc_1ZVKArmEQ"
      },
      "source": [
        "## So what's this notebook about?\n",
        "\n",
        "Sadly, **we won't deal with image generation in this notebook**. I know this might come as a dissappointment for some, but it is my belief that it will be far more valuable for you to see how to train a simple GAN that tries to imitate one-dimensional data. While certainly the classical way to learn this subject is to, e.g., generate new [handwritten numbers](http://yann.lecun.com/exdb/mnist/), I've seen too many details being lost or overshadowed by the architecture of the networks themselves instead of concentrating more on the training loop and what your model is actually trying to accomplish.\n",
        "\n",
        "Thus, in the broad scheme of things, the contents of this notebook are the following:\n",
        "\n",
        "* A quick overview of random numbers (we will explain how this is related)\n",
        "* The GAN training algorithm in pseudocode and code\n",
        "* Exercises for you to complete and send to me\n",
        "* (Appendices) How to sample from the latent space, why it's so hard to train a GAN, and how to evaluate one\n",
        "\n",
        "All in all, we will be using `PyTorch`, so this notebook will also aim to help you cement your understanding of this library. Lastly, this notebook is a bit wordy, so use the Table of contents to the left to guide yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roCAMaomPoBF"
      },
      "source": [
        "# Theory - Intuition\n",
        "\n",
        "We won't delve deep into the theory of GANs, as you can find this in the relevant papers and the class lectures. Instead, I wish to explain to you an equivalent way of understanding what GANs are actually doing. Note that if you prefer the way they were explained in the lecture, then feel free to skip to the **On To Programming** section ahead.\n",
        "\n",
        "I hope I don't lose you in the following explanation, as this is the key for this whole shebang, so feel free to ask me any questions if some details lose you or are too murky to traverse. You can  find a bit more theory details in the Appendices below, but I again urge you to refer to the referenced papers or websites."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-uR-K8Npc-P"
      },
      "source": [
        "## On Random Numbers\n",
        "\n",
        "Let us begin by asking a simple question: how are random numbers generated in your computer? In other words, [can a computer generate a pure random number?](https://engineering.mit.edu/engage/ask-an-engineer/can-a-computer-generate-a-truly-random-number/) Perhaps a completely unrelated question to ask, but bear with me for a moment, I assure you it will all make sense at the end.\n",
        "\n",
        "In essence, computers have trouble generating [pure random numbers](https://www.random.org/). Instead, they have an easier task producing [pseudorandom numbers](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) via a specific algorithm, which are a sequence of numbers that approximate the properties of random numbers but are completely deterministic, so long as you have the seed that generated them. A [**seed**](https://en.wikipedia.org/wiki/Random_seed) is the number that starts the pseudorandom number generator algorithm, and I am sure you have encountered it once before, either in the form [`np.random.seed(seed)`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.seed.html) or [`random.seed(seed)`](https://docs.python.org/3/library/random.html#random.seed), or in popular games like [Minecraft](https://www.minecraft.net) that require a seed to generate a world.\n",
        "\n",
        "Thus, when we set this seed, we will always generate the same sequence of random numbers thereafter, which is super useful for reproducing results. Let's look at a quick example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdPEQBptMKhd",
        "outputId": "a2a671ac-8be5-4572-a349-86d33e7ca0a5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# We set the seed:\n",
        "random.seed(42)\n",
        "# Let's print 5 uniformly distributed random numbers in [0, 1]:\n",
        "print([random.uniform(0, 1) for _ in range(5)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbWu9FjjU0Wi"
      },
      "source": [
        "If we set the same seed again and generate 5 uniformly distributed random numbers in $[0, 1]$, we start to generate the same sequence as before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81XSRwDtUtjX",
        "outputId": "0882969d-7a1f-477e-a194-1010b79be208"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "print([random.uniform(0, 1) for _ in range(5)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxxV80LhUw5S"
      },
      "source": [
        "Of course, if we continue printing more numbers, we will generate new ones that we haven't seen before, unless we set the seed again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGZ2zchOUuza",
        "outputId": "063418f4-a4a8-4a95-f1cd-b945e3ea03b2"
      },
      "outputs": [],
      "source": [
        "print([random.uniform(0, 1) for _ in range(5)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55opLOCaMLIb"
      },
      "source": [
        "[Many programmers have a preferred seed](https://blog.semicolonsoftware.de/the-most-popular-random-seeds/) that they always use for some reason, and as you will confirm in the code, I also have one of my own. Feel free to take a side in this pointless 'war', as we have all done before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWyH3vxUM3Hp"
      },
      "source": [
        "## Moving on to more complex distributions\n",
        "\n",
        "Now, it's 'easy' to generate uniformly distributed random numbers in $[0,1]$ by using [`random.random()`](https://hg.python.org/cpython/file/376c2d81d0e2/Lib/random.py#l356) which in turn uses the [Mersenne Twister](https://en.wikipedia.org/wiki/Mersenne_Twister) as the pseudorandom number generator algorithm. What happens when we wish to generate (pseudo)random numbers with a more complex distribution like, say, the [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution)?\n",
        "\n",
        "![Exponential Distribution](https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Exponential_probability_density.svg/800px-Exponential_probability_density.svg.png \"Exponential distribution\")\n",
        "\n",
        "Thanks to the [inverse transform method](http://www.columbia.edu/~ks20/4404-Sigman/4404-Notes-ITM.pdf), we can achieve just this! In concrete, we know we can generate random numbers $X$ with Cumulative Distribution Function or [CDF](https://en.wikipedia.org/wiki/Cumulative_distribution_function) $F_X$ via its *inverse CDF* $F_X^{-1}$. The process is as follows:\n",
        "\n",
        "1. Generate $U\\sim \\mathcal{U}(0,1)$\n",
        "2. Obtain $F_X^{-1}$\n",
        "3. Compute $X=F_X^{-1}(U)$, and $X$ will have the desired distribution!\n",
        "\n",
        "This might not be super clear, so here's an example on how to implement this:\n",
        "\n",
        "> **Example**: Suppose we wish to generate random numbers $X$ that are exponentially distributed with $\\lambda=0.5$, that is, $X\\sim\\text{Exp}(\\lambda=0.5)$, as the <font color='orange'>orange</font> curve in the figure above. We then get a bunch of numbers $U$ that are uniformly distributed in $[0,1]$, and then pass them through the inverse CDF of the exponential distribution. Luckily, there is a closed form of $F_X^{-1}$, which is:\n",
        "\n",
        "> $$ X=F_X^{-1}(U) = -\\frac{1}{\\lambda} \\log{(1-U)}\\sim\\text{Exp}(\\lambda) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFPSheLcRSc7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Get U, a bunch of uniformly distributed numbers in [0, 1]:\n",
        "U = np.random.uniform(size=2000)\n",
        "\n",
        "# 2., 3. Pass through the inverse CDF (which we know beforehand):\n",
        "lambda_ = 0.5\n",
        "X = - np.log(1 - U) / lambda_ # Note: we can also do: X = -np.log(U) / lambda_ ; why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUfr45NrzSEf"
      },
      "source": [
        "$X$ above will be exponentially distributed with $\\lambda=0.5$. To really illustrate this, we can plot their distributions via a simple histogram, first of $U$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm6cvjyrJ33s",
        "outputId": "773f220b-df47-49dd-b445-b2607323db0a"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn==0.10 # We need a previous version of Seaborn for the plots (restart the notebook if prompted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "BqhFl0yMR1T0",
        "outputId": "73db4e5a-6611-43a7-db35-43bc95dbba14"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.distplot(U, norm_hist=True, kde=True,\n",
        "             rug = False, rug_kws={\"alpha\": 0.15})\n",
        "plt.title('Uniform Distribution in [0, 1]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg9wBGPDzJWL"
      },
      "source": [
        "And now of $X$, which has the expected exponential distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "E4qSDYJCk0Dy",
        "outputId": "2bf55c53-eef2-4516-80ca-4cfefb5d6d81"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.distplot(X, norm_hist=True, kde=True,\n",
        "             rug=False, rug_kws={\"alpha\": 0.15})\n",
        "plt.title(f'Exponential Distribution with $\\lambda={lambda_}$')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dreGmIXVcJdF"
      },
      "source": [
        "Note that in both plots, histogram agrees with out theoretical results, but the KDE is not really exactly what we expected, since it uses a smoothing function. We will focus on the KDE on the latter sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js1h0_a0P0i4"
      },
      "source": [
        "## Higher Dimensional Random Numbers\n",
        "\n",
        "So what is happening, why am I wasting your time talking about random numbers you might ask. Sadly for you, the main reason is because before starting my Ph.D., I actually studied Physics and Applied Mathematics, so I love subjects like this one.\n",
        "\n",
        "The second reason is a bit more warranted and  straightforward: we can represent images as a high-dimensional vectors. Indeed, remember that each pixel has three channels (if we are working with RGB images that is), so we can see an image of size $224\\times224\\times3$ as being just a *massive* vector.\n",
        "\n",
        "With this in mind, we can generate a random image like so then:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "YepCRbw-dz7l",
        "outputId": "acf7b4d6-c29c-4c01-f934-f5da142d799d"
      },
      "outputs": [],
      "source": [
        "random_image = np.random.randint(low=0, high=255, size=(224, 224, 3))\n",
        "\n",
        "plt.imshow(random_image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUyFTE3yci_D"
      },
      "source": [
        "Of course, reality is a bit more nuanced than that. Two things should be noted: ***first***, no matter how many times you run the above code, you won't generate any image that has any sort of significant structure (i.e., you won't be generating a person's face anytime soon). That is simply because the number of images that are gibberish is much, much larger than the number of meaningful images of the desired size $224^2$.\n",
        "\n",
        "Indeed, how many *unique* images of size $224^2$ are there? Since each pixel has three channels and we continue to assume they are of 24 bits (each channel in the range 0 to 255), then the total number of unique images is:\n",
        "\n",
        "$$(|R|\\times|G|\\times|B|)^{W\\times H}=(256\\times256\\times256)^{224\\times224} = (2^{24})^{50176} =2^{1204224}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p2eJGq383X9"
      },
      "source": [
        "An astronomically large number that makes the [$1.2$ trillion images taken in 2018](https://theconversation.com/of-the-trillion-photos-taken-in-2018-which-were-the-most-memorable-108815) pale in comparison. Given that we'll still be around the same order of magnitude in the current year (around $2^{40}$), we can see that just the number of possible images of size $224\\times 224$ already overshadows the number of images taken per year.\n",
        "\n",
        "> As a side note, we should note that while the number of possible images of size $224^2$ is large, it is still a **finite** number nonetheless. To me it sort of begs the question: [is graphic art finite?](https://www.researchgate.net/profile/Kim_Williams10/publication/226211320_From_Tiling_the_Plane_to_Paving_Town_Square/links/0c9605375fd52b78fd000000/From-Tiling-the-Plane-to-Paving-Town-Square.pdf#page=30) Even [music isn't safe of this question either](https://youtu.be/DAcjV60RnRw), so we could honestly just ask if art is finite in and of itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZKQkZQL88ZB"
      },
      "source": [
        "How is it possible then to take a random vector and produce with it an actual image, let alone an image with interesting features? The implausibility of this task may seem daunting, but there is a way...\n",
        "\n",
        "This brings us to our ***second*** point: perhaps trying to generate any meaningful image of size $224^2$ is too broad, what if we make it more specific? Specifically, what if we focus on the images that are solely of _**dogs**_? We could imagine, then, that all these dog images exist in a subspace of the $2^{1204224}$ dimensional space that represents *all* the images of this size. We can use the following figure for guidance:\n",
        "\n",
        "![Image Manifold](https://user-images.githubusercontent.com/24496178/75723169-0e422d80-5cdc-11ea-88e8-0c0685a07372.png \"Image Manifold\")\n",
        "[Image Source](https://www.oreilly.com/library/view/generative-deep-learning/9781492041931/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOttb-cV9ARs"
      },
      "source": [
        "We can see that some areas of this high-dimensional space contain images of cars, others images of apples, and so on. The [Manifold Hypothesis](https://arxiv.org/abs/1310.0425) for our case will say as follows: there exists a lower-dimensional manifold that contains all the images of dogs, and this manifold is characterized by a distribution $p_{\\text{dogs}}$. So if we are able to find this distribution, then we can simply sample from it and we'll have a brand new image of a dog!\n",
        "\n",
        "Imagine, if you will, a *closed-form* equation for $p_{\\text{dogs}}$. That is, an equation that perfectly describes the probability that an image $x$ of size $224^2$ is of a **dog**. A nigh impossible task you may say, and you may be right! However, we aren't interested in an ***explicit*** version of this probability distribution, just an ***implicit*** one so that we may sample from it, and we have just described such a mechanism above via the inverse transform method:\n",
        "\n",
        "1. Generate a sequence of *easy* random numbers $U$, such as Uniformly or Normally distributed\n",
        "2. Find $F_{\\text{dogs}}^{-1}$\n",
        "3. Get $X=F_{\\text{dogs}}^{-1}(U)$, which should be a sequence of many images of dogs (if training proceeds as intended)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkh_7oOz9DWq"
      },
      "source": [
        "Now we can just focus on one problem: how exactly will we find this inverse CDF, $F_{\\text{dogs}}^{-1}$, in step 2 and then use it in step 3?  Writing such a function explicitly as the example we did before with the Exponential distribution seems, again, impossible. However, remember that neural networks are [universal function approximators](https://en.wikipedia.org/wiki/Universal_approximation_theorem), so they can be used exactly for this purpose!\n",
        "\n",
        "Thus, this is the whole beauty of GANs: the Generator $G$ will act as $F_{\\text{dogs}}^{-1}$, so we need only to feed it random vectors of our chosen *easy* distribution, and the output will be an image that should, hopefully, follow the distribution we wish, in this case of dogs:\n",
        "\n",
        "$$G(z) = x \\sim p_{\\text{dogs}}$$\n",
        "\n",
        "In short, we don't need to know the explicit form of this distribution, as the Generator will do it for us in an implicit way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeHyqzU6QAWO"
      },
      "source": [
        "## A Game Theory Perspective\n",
        "\n",
        "Alright, so how do we actually achieve this tremendous task? We start with a clever trick: from a Machine Learning perspective, we've usually dealt with [discriminative models](https://en.wikipedia.org/wiki/Discriminative_model) by training a Neural Network (Discriminator) in a Supervised Learning way. For example, if we wish to classify some images of handwritten numbers as being <font color='green'>Real</font> or <font color='red'>Fake</font>, we have the classical setting:\n",
        "\n",
        "![A Discriminative network](https://user-images.githubusercontent.com/24496178/73466532-44f5f280-4382-11ea-9fc7-3dadeacda596.png \"A Discriminative network\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6N1ErICBKFn"
      },
      "source": [
        "The trick lies in adding another component into this scheme: another NN, the Generator. Why not let both of these networks compete with one another in a clever way, producing exactly the output that we are looking for?\n",
        "\n",
        "![Typical GAN Architecture](https://user-images.githubusercontent.com/24496178/73466054-96ea4880-4381-11ea-9898-3e0dcbfaa451.png \"Typical GAN Architecture\")\n",
        "[Image Source](https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/)\n",
        "\n",
        "Since we are pitting them against each other, the Generator $G$ will try to fool the Discriminator $D$ by generating *fake* data, whereas $D$ will try to distinguish the *real* from the *fake* data. As such, we will define a [minimax](https://en.wikipedia.org/wiki/Minimax) game or more specifically, a zero-sum game. That is, one player will wish to minimize the objective function, whereas the other player wishes to maximize it.\n",
        "\n",
        "Let us denote by $p_\\text{data}$ the distribution of our dataset $x$, <font color='green'>$p_g$</font> the distribution of our generated data $G(z)$, and $p_z$ the distribution of our prior *easy* distribution $z$. As such, we will have that:\n",
        "\n",
        "$$D:x\\to[0,1] \\qquad G:z\\to x \\qquad x\\sim p_\\text{data}, z\\sim p_z$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNxZS_TUBOoH"
      },
      "source": [
        "We use the following objective function explained in the lectures:\n",
        "\n",
        "$$\n",
        "V(D, G)=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\mathrm{data}}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}}(\\boldsymbol{z})[\\log (1-D(G(\\boldsymbol{z})))]\n",
        "$$\n",
        "\n",
        "Specifically, one player will seek to minimize it, while the other will seek to maximize it:\n",
        "\n",
        "$$\n",
        "\\min_G \\max_D V(D, G)= \\min_G \\max_D \\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\mathrm{data}}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}}(\\boldsymbol{z})[\\log (1-D(G(\\boldsymbol{z})))]\n",
        "$$\n",
        "\n",
        "> This makes sense in the following way: $D$ wants to distinguish between real and fake images, so then $D(x)$ should be close to $1$, whereas $D(G(z))$ should be close to $0$. On the other hand, since $G$ wishes to fool $D$, then it seeks to push $D(G(z))$ close to $1$, and we thus arrive at this minimax setting. Try plotting these functions to verify this conclusion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm0KJctIBRh2"
      },
      "source": [
        "Note that our objective is basically a saddle point, so the training will be extremely unstable. Indeed, training a GAN is challenging, and some caveats are discussed in the Appendices below.\n",
        "\n",
        "![Game theory POV](https://user-images.githubusercontent.com/24496178/75048880-8a14cc80-54c9-11ea-87c1-f6e6abf4b82e.png \"Game theory POV\")\n",
        "[Image Source](https://www.iangoodfellow.com/slides/)\n",
        "\n",
        "This section is basically a summary of what is seen in the lectures, so consult those if you felt a bit lost here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8471e6qzwTZN"
      },
      "source": [
        "### On Training a GAN\n",
        "\n",
        "Now, to conclude: our Generator will output data with a distribution <font color='green'>$p_{g}$</font>, but we wish this to be close to the real data, $p_\\text{data}$. In the following image, we move to the right as training progresses, with <font color='blue'>$p_{d^*}$</font> being the discriminative distribution along the domain of $x$. **Take special attention, as this is the figure we will try to recreate in this notebook.**\n",
        "\n",
        "![GAN Training Distribution](https://user-images.githubusercontent.com/24496178/73085503-1635d300-3ecf-11ea-85de-1514d8085c43.png \"GAN Training Distribution\")\n",
        "[Image Source](https://arxiv.org/abs/1406.2661)\n",
        "\n",
        "So, at the beginning (a), the distribution of the generated and real data is distant, but as training progresses, they will (hopefully) match, and our Discriminator kind of knows how to classify each point. In (b), we train $D$ and it converges to the optimal solution:\n",
        "\n",
        "$$D^{*}(x)=\\frac{p_\\text{data}(x)}{p_\\text{data}(x)+p_g(x)}$$\n",
        "\n",
        "We see that <font color='blue'>$p_{d^{*}}$</font> reflects this. Then, in (c), we train the Generator using the signal from the Discriminator $D^{*}$ and see that the generated distribution gets pushed closer to the real distribution.\n",
        "\n",
        "We continue this process until we reach (d), where both distributions match perfectly and, if this is the case, $D^{*}(x)=1/2$ always (as $p_\\text{data} = p_g$). In other words, $D$ won't be able to differentiate the generated from the real data, hence it will always output a probability of $1/2$ of the input being real, i.e. a coin flip!\n",
        "\n",
        "This will almost never happen, but one can only dream. Therefore, be attentive whenever the Discriminator consistently outputs $1/2$, as it may have converged. For another more in-depth explanation on the topic, check [Colin Raffel's blog post](https://colinraffel.com/blog/gans-and-divergence-minimization.html).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKXpR-QXpFCF"
      },
      "source": [
        "# On To Programming\n",
        "\n",
        "This notebook will assume you have used [`PyTorch`](https://pytorch.org/) before, or at least you are acquainted with it. Should a refresher be needed, check out this repository: [Grokking `PyTorch`](https://github.com/Kaixhin/grokking-pytorch).\n",
        "\n",
        "Let's get down to business and load the pertinent packages we'll need from this section onward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "743Sy0N4JGWJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "import time\n",
        "\n",
        "from typing import Union, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8ZKl0e6S0-X"
      },
      "source": [
        "The latter will be used for [type hints](https://www.python.org/dev/peps/pep-0484/), of which some find useful and others won't. I apologize if you find yourself in the latter group. We can get the `PyTorch` version that is installed (and is useful when installing the correct [CUDA toolkit](https://anaconda.org/anaconda/cudatoolkit) version if using a GPU) like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzGr8Gc-JfH1",
        "outputId": "0e9823f2-6038-493f-da64-7f0c806367bc"
      },
      "outputs": [],
      "source": [
        "print(f'PyTorch version: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP3CmrsGsutZ"
      },
      "source": [
        "The following cell will display a message only if you are using a GPU. In this notebook, a GPU won't be necessary (no *significant* speedup was observed due to the complexity and size of the data), but you are free to use one if you so wish:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPHIi6jEPidz"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    for i in range(n_gpu):\n",
        "        high, low = torch.cuda.get_device_capability(i)\n",
        "        print(f'GPU {i}, Device: {torch.cuda.get_device_name(i)}, Compute Capability: {high}.{low}')\n",
        "\n",
        "    print(f'Current device: {torch.cuda.current_device()}') # CUDA devices start counting from 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAQe1GGhtJG4"
      },
      "source": [
        "You should expect the output to be `0`. In the future, if you are wishing to work with multiple GPUs such as in a server, perhaps [this guide](https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html) will be of your interest.\n",
        "\n",
        "In any case, we will be using either `cpu` or `cuda` (GPU), so we can define our `device` like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqMAaGmq3g0x",
        "outputId": "c1856743-1785-4e41-b82d-a092a2a076cb"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgkkSqrHi5gX"
      },
      "source": [
        "We will be allocating our models and data to this `device`, so don't forget it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZwnNYYJR8S3"
      },
      "source": [
        "# The Training Data\n",
        "\n",
        "Let's get some training data. We can of course get some one-dimensional data from the wild and try to mimic it; however, it's best to be able to easily define the data and know beforehand what to expect in order for the whole GAN training loop to become familiar.\n",
        "\n",
        "This is exactly what we will do: our data will be drawn from a Gaussian distribution with mean $\\mu=4.0$ and standard deviation $\\sigma=0.5$. In other words, $p_{\\text{data}}=\\mathcal{N}(4.0, 0.5^2)$. Let's go ahead and create this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZMdqQfIMPVE"
      },
      "source": [
        "## [Normal Distribution](https://pytorch.org/docs/stable/distributions.html#normal): $p_{\\text{data}}=\\mathcal{N}(\\mu, \\sigma^2)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsAfc9xVjnj2"
      },
      "source": [
        "The following class definition is not really necessary, but it makes it easier to modify the values of the mean $\\mu$ and standard deviation $\\sigma$ of our data. Likewise, at the end of the notebook you'll have other more complex distributions to choose from, all of which follow this same structure, so this will make it easier to understand those other distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ-xeuSiP3iE"
      },
      "outputs": [],
      "source": [
        "class NormalDistribution:\n",
        "    def __init__(self, mu: float =4.0, sigma: float =0.5):\n",
        "        self.mu = torch.tensor([mu])\n",
        "        self.sigma = torch.tensor([sigma])\n",
        "\n",
        "    def sample(self, N: int = None, seed: int = 42):\n",
        "        # Set the seed for reproducibility:\n",
        "        torch.manual_seed(seed)\n",
        "        # Define the distribution:\n",
        "        N = 1 if N is None else N\n",
        "        m = torch.distributions.normal.Normal(loc=self.mu, scale=self.sigma)\n",
        "        samples = m.sample([N])\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikL4cxOIANA2"
      },
      "source": [
        "Then, we will simply use the `sample` method in order to obtain the correct quantity of data points we wish to use by simply setting `N`. For now, let's use `N=10000`, with the defined mean and variance we had discussed before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFJNiJAwJXDj",
        "outputId": "67d3f616-36b5-49b9-be67-8eb428f38a0e"
      },
      "outputs": [],
      "source": [
        "data = NormalDistribution().sample(10000)\n",
        "\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvviK7hkAVEe"
      },
      "source": [
        "We now calculate the mean and standard deviation of the `data`. While we know the *real* mean and standard deviation of our data distribution, namely $\\mu=4$ and $\\sigma=0.5$, at the end the Generator will only have access to the `data` we feed it and will try to approximate this sample's parameters. We will then calculate this sample mean and standard deviation and store them in the variables `actual_mean` and `actual_std`, to be used for some plotting later on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjHA8i8xLw0n",
        "outputId": "29863ea3-a565-4126-ee22-b6154b8d9ce2"
      },
      "outputs": [],
      "source": [
        "actual_mean = torch.mean(data)\n",
        "actual_std = torch.std(data)\n",
        "\n",
        "print(f'Data mean: {actual_mean:.4f}, standard deviation: {actual_std:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdLdPA1Vm7BD"
      },
      "source": [
        "We can see that they don't differ by much from the actual ones, but it's best to keep them stored to better visualize what the Generator is trying to approximate.\n",
        "\n",
        "Now, let's plot this data: we will use a [kernel density estimate](https://en.wikipedia.org/wiki/Kernel_density_estimation) from [`Seaborn`](https://seaborn.pydata.org/generated/seaborn.kdeplot.html) to better visualize the distribution of the data, along with a histogram in the background. We also plot the individual datapoints in the bottom as a [rugplot](https://seaborn.pydata.org/generated/seaborn.rugplot.html), resulting in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "JF4pvzvzJeYs",
        "outputId": "d8211404-9293-4ff9-b600-bf61a2401034"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.distplot(data,\n",
        "             norm_hist=True,\n",
        "             rug=True,\n",
        "             kde_kws={\"color\": \"k\",\n",
        "                      \"label\": \"Data Distribution\",\n",
        "                      \"linestyle\":\":\",\n",
        "                      \"linewidth\": 3},\n",
        "             rug_kws={\"alpha\": 0.15})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK_Lj1QTnvZi"
      },
      "source": [
        "The data seems to be exactly what we expected: a normal distribution centered at $4.0$ with variance $\\sigma^2=0.25$. Of course not a perfect Gaussian curve, but close enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kpolv4zficY"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "In general, we won't be using all our training data at the same time, but partition it into **batches**. Remember that it is advisable to have the **batch size** to be a [power of 2](https://datascience.stackexchange.com/a/20193) to fully use the power of your GPU (or, depending on your architecure, even a [power of 8](https://devblogs.nvidia.com/optimizing-gpu-performance-tensor-cores/)).\n",
        "\n",
        "Let's use `batch_size = 1024`, but this can be easily modified whenever you so wish:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeDtEsjyt4H_"
      },
      "outputs": [],
      "source": [
        "batch_size = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxxBxL-Qt4lO"
      },
      "source": [
        "> Even though `1024` is a power of 2, I just want to note that generally in Deep Learning, we don't go too crazy with the batch size, i.e., [$2\\leq \\texttt{batch_size}\\leq32$](https://arxiv.org/abs/1804.07612). The good/bad news is we aren't really going to do ***Deep*** Learning in this notebook, plus our data is extremely simple. As such, using a small batch size won't really help us, and I hope you try this later on. On the other hand, it is not unfeasible to go for larger batch sizes than $32$, which is what the authors of [BigGAN](https://arxiv.org/abs/1809.11096) showed in the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ3LcecDVUMS"
      },
      "source": [
        "### Data Transformations\n",
        "\n",
        "When you typically load your dataset with `PyTorch`, you should do so with some [transformations](https://pytorch.org/docs/stable/torchvision/transforms.html): `.ToTensor()`, `Normalize()` are perhaps the most important, but of course there are many more. Look into [this guide](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) for writing more custom transformations.\n",
        "\n",
        "This is a classical preprocessing step, moreso when your dataset consists of images that you wish to resize, crop, rotate, etc. (typically done so that your model is better able to generalize). Take note that you shouldn't be rotating or randomly cropping for GANs applied to images; it is only common to [mirror-flip at most](https://github.com/NVlabs/stylegan2#training-networks). This is because some datasets only make sense when they're upright (e.g., human faces) or cropped at specific places (such as the center of the image). However, this also depends on your dataset, so don't let me stop you from trying other approaches. This is different than the *dataset augmentations* that have appeared for training GANs with small datasets (such as [StyleGAN2-ADA](https://arxiv.org/abs/2006.06676) or [bCR/zCR](https://arxiv.org/abs/2002.04724)), as these have to be carefully applied so as to not to leak to the Generator, so don't confuse these.\n",
        "\n",
        "A quick example of using the transformations: the next code block would first transform our image data (as it consists of `NumPy` arrays) to a Tensor, and then normalize it by using a per-channel mean and standard deviation (in the strict definition of the word, what we are doing here is [standardization](https://en.wikipedia.org/wiki/Standard_score), but who am I to rename things at this point?):\n",
        "\n",
        "```python\n",
        "data_transforms = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=(mean1, mean2, mean3), std=(std1, std2, std3))\n",
        "                                      ])\n",
        "```\n",
        "\n",
        "An interesting discussion on both how to calculate the mean and standard deviation of your dataset can be found [here](https://discuss.pytorch.org/t/about-normalization-using-pre-trained-vgg16-networks/23560). Make sure to read the full thread, as well as the revisions made to the accepted answers.\n",
        "\n",
        "We won't be using any transformations, so we can get our [`dataloader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gyi9H9VOKwj"
      },
      "outputs": [],
      "source": [
        "dataloader = torch.utils.data.DataLoader(data,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True) # !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ9yFLVF4Em9"
      },
      "source": [
        "`shuffle=True` is crucial, when we don't wish to somehow leak information to our model, should our dataset be neatly separated in different subdirectories. This is not the case here, but it won't hurt our results.\n",
        "\n",
        "We will *iterate* through the `dataloader`, getting a fresh batch of random data of size `batch_size`, up until the last batch which should have a size of `1024*(10000/1024-10000//1024)=784`. In order to get a batch, we can simply create an iterator object via [`iter`](https://docs.python.org/3.8/library/functions.html#iter) and load the `.next()` batch like so:\n",
        "\n",
        "```python\n",
        "dataiter = iter(dataloader)\n",
        "x = dataiter.next()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pncn2HCqrmS"
      },
      "source": [
        "It is more usual to [`enumerate`](https://docs.python.org/3/library/functions.html#enumerate) the batches, like we do next when plotting them. Note that we can see that the expected Gaussian $\\mathcal{N}(4, 0.25)$ can be somewhat inferred per batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "9-jpNXkCTC6H",
        "outputId": "33931542-082b-47c0-b31a-eccbe7ebecd1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "for i, d in enumerate(dataloader):\n",
        "    label = f'Batch {i + 1},  Size {len(d)}'\n",
        "    sns.distplot(d, hist=False, kde=True, label=label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q2o5Z4druMw"
      },
      "source": [
        "> A caveat: with images, we will of course use smaller batches, and each of these batches won't necessarily represent the general distribution of our dataset. You can imagine this while picturing our previous dataset of dogs: some batches might be of one specific breed, others might be of mixed breeds, so our statistics may be all over the place!\n",
        "\n",
        "> We harken back to [BigGAN](https://arxiv.org/abs/1809.11096): the authors noted that large batches helped produce better quality images. Indeed, their batch size was $256$ with $8$ gradient accumulations, translating into a batch size of $2048$. Using 8 [V100](https://www.nvidia.com/en-us/data-center/v100/) GPUs, it takes the model [15 days of training time](https://github.com/ajbrock/BigGAN-PyTorch#how-to-use-this-code) to reach the desired number of iterations. As such, this is why only companies like Google are able to train such a monstruous model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9s15wv1R6E4"
      },
      "source": [
        "# Generator\n",
        "\n",
        "Finally, we will start with our neural network coding. Remember that the input of the Generator will be a simple random vector, so we must first define this vector space, which we will do next:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMQvS6nNQbZq"
      },
      "source": [
        "## The latent space $\\mathcal{Z}$\n",
        "\n",
        "In the literature, this *easy* vector space from which we take the simple random vectors is called the **latent space**. Historically, the random vectors being used were Uniformly distributed, but nowadays it is common for them to be Normally distributed, that is, $p_z = \\mathcal{N}(0,1)$.\n",
        "\n",
        "Thus, the only thing to define is the dimensionality of this vector space, or $|\\mathcal{Z}|$. Typically, the more complicated the task, the higher this dimension. For example, the [DCGAN](https://arxiv.org/abs/1511.06434) used $|\\mathcal{Z}|=100$, and it set the standard that many GAN architectures used thereafter: in some cases, unnecessary, in others, not complex enough.\n",
        "\n",
        "For our case, since we are dealing with simple one-dimensional data, we won't be needing such a high number. Let's stick with $|\\mathcal{Z}|=5$ and see how this works for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqEJCF2lQdO_"
      },
      "outputs": [],
      "source": [
        "latent_dim = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvYpUwlU5nwS"
      },
      "source": [
        "Let's define a function that will make it easy for us to produce a random set of latent vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzCg8NZlJkWs"
      },
      "outputs": [],
      "source": [
        "def get_latents(N: int, latent_dim: int, seed: int = None) -> torch.Tensor:\n",
        "    \"\"\" Sample N latents from a Normal distribution of dimension latent_dim.\n",
        "        For reproducibility's sake, we can fix the seed.\n",
        "    \"\"\"\n",
        "    size = (N, latent_dim)\n",
        "    generator = torch.Generator(seed=seed) if seed is not None else None\n",
        "    latents = torch.randn(*size, device=device, generator=generator)\n",
        "    return latents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XInepHHGTZWA"
      },
      "source": [
        "A classical question to ask yourselves is: how do you know whether or not $G$ is indeed generating better outputs as training progresses? Can we rely solely on the losses of our networks? There is an indirect solution: fix a set of latent vectors, which we will call `fixed_latent` that we'll leave unchanged, and see how the output `G(fixed_latent)` evolves over time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RzSpzdnvdxq",
        "outputId": "115a339f-73e5-4603-cd8f-ab3b5b26ba6e"
      },
      "outputs": [],
      "source": [
        "fixed_latent = get_latents(N=batch_size, latent_dim=latent_dim)\n",
        "print(fixed_latent.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ame3Vg9ESvpC"
      },
      "source": [
        "We will pass these fixed latent vectors through $G$, (hopefully) producing better and better results as training progresses.\n",
        "\n",
        "For generating images, this process will be more intuitive: at the beginning we will see that the Generator produces nonsense, but as training progresses, the generated images will get closer and closer to the ones we wish to generate. For example, in the following GIF, a GAN is trying to generate new MNIST numbers:\n",
        "\n",
        "![DCGAN MNIST training](https://raw.githubusercontent.com/znxlwm/tensorflow-MNIST-GAN-DCGAN/master/MNIST_DCGAN_results/MNIST_DCGAN_generation_animation.gif \"DCGAN Mnist training\")\n",
        "[Image Source](https://github.com/znxlwm/tensorflow-MNIST-GAN-DCGAN)\n",
        "\n",
        "This type of visualization only makes sense if we are using the same latent vector for each image, so keep this in mind!\n",
        "\n",
        "Another example is the following video I set up for you, of which I explain a bit better in the Appendices. In this video, we see how the image generation evolves for a StyleGAN2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ngDQgMhT_JND",
        "outputId": "ca43aba8-2bfa-4240-feb1-bae92d1ac489"
      },
      "outputs": [],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('W2gboP-Xmgs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL2Qo-mM4IFI"
      },
      "source": [
        "## The Generator\n",
        "\n",
        "Now, finally we define our Generator! It will be a simple network, as our real data is also very simple. It will have `1` hidden layer, with `15` hidden neurons, with `1` output (as our real data is one-dimensional):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-exeIVXTcGQ"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim: int = 5, hidden_dim: int = 15, output_size: int = 1):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Input is the latent vector (ReLU output)\n",
        "            nn.Linear(in_features=latent_dim, out_features=hidden_dim),\n",
        "            # We use ReLU nonlinearity:\n",
        "            nn.ReLU(inplace=True),\n",
        "            # Hidden layer (linear output)\n",
        "            nn.Linear(in_features=hidden_dim, out_features=output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbueP4B-7c29"
      },
      "source": [
        "For our ReLU function, we don't wish to make a copy of the weights, so instead we have modified the values in-place via [`inplace=True`](https://discuss.pytorch.org/t/whats-the-difference-between-nn-relu-and-nn-relu-inplace-true/948). Be careful of not using other in-place operations (such as `out += res` in `forward`), as there will be errors. See [here](https://github.com/pytorch/pytorch/issues/5687) for a discussion on this topic.\n",
        "\n",
        "Let's get our `generator` and print it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAtGtLghTvIn",
        "outputId": "a4eceb19-e445-4bb7-f641-11f1289c1ad1"
      },
      "outputs": [],
      "source": [
        "generator = Generator(latent_dim=latent_dim, hidden_dim=15).to(device)\n",
        "\n",
        "print(generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjmmismwuS9O"
      },
      "source": [
        "The parameter values of our model can also be printed like so (though this is not advisable for more complex networks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W3dKDzFh9oC",
        "outputId": "cddcc30c-efd5-4752-9126-4681e0fad563"
      },
      "outputs": [],
      "source": [
        "for i, param in enumerate(generator.parameters()):\n",
        "    print(param.size())\n",
        "    print(param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HUnKVhdgBtP"
      },
      "source": [
        "Sadly, this won't tell us much about our model, like the `summary` we have in [Keras](https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary). Luckily there is now a solution: use [`torchsummary`](https://github.com/sksq96/pytorch-summary)!\n",
        "\n",
        "Should this package not be installed, run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn3aHWnZRvG7",
        "outputId": "ae52eb06-55f2-4203-aebb-795dd286a403"
      },
      "outputs": [],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERKIwHv8fjER",
        "outputId": "4c0a533c-22be-487d-b24c-8f7a72d0aace"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model=generator,\n",
        "        input_size=(latent_dim, ),\n",
        "        batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeyYW1PPR9px"
      },
      "source": [
        "# Discriminator\n",
        "\n",
        "The discriminator $D$ will take in a datapoint $x$ (be it an image or in our case a real number) and will output the probability that it's class is $\\text{real}$, or:\n",
        "\n",
        "$$D(x)=\\mathbb{P}[x | y=\\text{real}]=1-\\mathbb{P}[x|y=\\text{fake}]$$\n",
        "\n",
        "Thus we will use the `sigmoid` activation function as the final layer, with `1` neuron as output. We will give it only `1` hidden layer, but this time with `25` hidden neurons:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB0WIPkHPNfG"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size: int = 1, hidden_dim: int = 25):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            # Input is one-dimensional\n",
        "            nn.Linear(in_features=input_size, out_features=hidden_dim),\n",
        "            # We use ReLU nonlinearity\n",
        "            nn.ReLU(inplace=True),\n",
        "            # Our output is a probability, so we use 1 output neuron with sigmoid:\n",
        "            nn.Linear(in_features=hidden_dim, out_features=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbPDcsZy8Sj_"
      },
      "source": [
        "We do the same as before: we define our `discriminator` and print it, along with the parameter values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaYeH6XNWP07",
        "outputId": "80daa0bd-f7c6-440c-8966-daef27aa43da"
      },
      "outputs": [],
      "source": [
        "discriminator = Discriminator(hidden_dim=25).to(device)\n",
        "\n",
        "print(discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVO9zOnvvfSE",
        "outputId": "72751313-be8c-4f79-ec24-d50f1c866178"
      },
      "outputs": [],
      "source": [
        "for i, param in enumerate(discriminator.parameters()):\n",
        "    print(param.size())\n",
        "    print(param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N93YAeIPx459"
      },
      "source": [
        "Again, this doesn't add much insights to this model, so we can print the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T7w2cStx8Gm",
        "outputId": "91a03ed8-39b1-4a5b-8661-c1b83257c3c4"
      },
      "outputs": [],
      "source": [
        "summary(model=discriminator,\n",
        "        input_size=(1, ),\n",
        "        batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W4DL76GcaTp"
      },
      "source": [
        "# Weights initialization\n",
        "\n",
        "We could've made the initialization whilst defining each network above, but it is best practice to define a function like we will do now, in order to apply it to any network we wish. For all the weights in both hidden networks, we will use the [Kaiming initialization](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_), except for the bias which we will [zero-initialize](http://cs231n.github.io/neural-networks-2/#init):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lihDId9EccGx"
      },
      "outputs": [],
      "source": [
        "def weights_init(module):\n",
        "    if isinstance(module, nn.Linear):\n",
        "        # Initialize the weights with Kaiming Normal (in-place):\n",
        "        nn.init.kaiming_normal_(module.weight)\n",
        "        # Initialize the bias with zeros (in-place):\n",
        "        module.bias.data.fill_(0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYwl37kxZuAI"
      },
      "source": [
        "So, in order to use this `weights_init` function, we recursively apply it to all modules in each of our models via `model.apply()`. Let's start with the Generator like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoXYY2x4cgsL",
        "outputId": "fcb112f8-d6fc-4070-d709-d4f6900564ec"
      },
      "outputs": [],
      "source": [
        "generator.apply(weights_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wulFjxg4dvC1"
      },
      "source": [
        "We can examine the values of our parameters and see that they have been indeed correctly initialized as intended:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DS3lLx3f02C",
        "outputId": "bec37154-fa71-4971-9b21-ffb1d46fad2c"
      },
      "outputs": [],
      "source": [
        "for param in generator.parameters():\n",
        "    print(param.size())\n",
        "    print(param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVnxNMI4d00V"
      },
      "source": [
        "Likewise for the Discriminator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJj9QcT1vk5n",
        "outputId": "d247ca72-b94b-4a70-d06e-3064bbdb8048"
      },
      "outputs": [],
      "source": [
        "discriminator.apply(weights_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nA5V__fvqLD",
        "outputId": "2566628e-daa6-434e-ef53-e12c0d19f806"
      },
      "outputs": [],
      "source": [
        "for param in discriminator.parameters():\n",
        "    print(param.size())\n",
        "    print(param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYcHQCzNEQ5H"
      },
      "source": [
        "For a more thorough discussion on weight initialization, check the `PyTorch` forums such as [this one](https://discuss.pytorch.org/t/how-to-fix-define-the-initialization-weights-seed/20156)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZQn5Yp2E16g"
      },
      "source": [
        "# Criterion\n",
        "\n",
        "Remember that the signal that the Discriminator $D$ is doing a good job will be given in the form:\n",
        "\n",
        "$$ \\log{D(x)} + \\log{(1-D(G(z)))}$$\n",
        "\n",
        "which the Discriminator wishes to maximize. On the other hand, the signal that the Generator $G$ is doing a good job wil be given in the form:\n",
        "\n",
        "$$ \\log \\left( 1-D(G(z)) \\right) $$\n",
        "\n",
        "which the Generator wishes to minimize. The easiest setting is to define the *real* image label as 1 and *fake* image label as 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdgCzO2BYHAB"
      },
      "outputs": [],
      "source": [
        "real_label = 1.0\n",
        "fake_label = 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eySywC2PiQ0v"
      },
      "source": [
        "  * ***Note***: You can also try experimenting with `real_label = 0.9`, which is called one-sided label smoothing. Section 4.2 of the [2016 NeuriPS GAN Tutorial](https://arxiv.org/abs/1701.00160) by Goodfellow has a further explanation on this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfZOQlvYYGBp"
      },
      "source": [
        "Therefore, we will use the [binary crossentropy loss function](https://en.wikipedia.org/wiki/Cross_entropy), defined as:\n",
        "\n",
        "$$J(\\mathbf{w}) = -\\frac{1}{N} \\sum_{n=1}^{N}\\left( y_n \\log \\hat{y}_n + (1-y_n) \\log \\right( 1-\\hat{y}_n \\left)  \\right)$$\n",
        "\n",
        "In `PyTorch`, this is simply the [`BCELoss()`](https://pytorch.org/docs/stable/nn.html#bceloss), which will be our criterion for whether either network is doing good. We initialize it like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mtf0PHfsE1r4"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxYK_fySWJLv"
      },
      "source": [
        "When $y=1$, the Discriminator will know that it's being trained on a real batch of data, whereas when $y=0$, it's being trained on a batch of fake (generated) data. We will see how we can use this setting to use the signal from the Discriminator to train the Generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFXfCWlYQMc2"
      },
      "source": [
        "# Training Loop\n",
        "\n",
        "Remember the equation:\n",
        "\n",
        "$$\n",
        "\\min _{G} \\max _{D} V(D, G)=\\min _{G} \\max _{D} \\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z})))]\n",
        "$$\n",
        "\n",
        "In practice, since both the Generator and Discriminator will be neural networks, we can then define this game via their respective parameters/weights $\\theta_g$ and $\\theta_d$ like so:\n",
        "\n",
        "$$\n",
        "\\min _{\\theta_g} \\max _{\\theta_d} V(\\theta_d, \\theta_g)=\\min _{\\theta_g} \\max _{\\theta_d} \\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}(\\boldsymbol{x})}[\\log D_{\\theta_d}(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1-D_{\\theta_d}(G_{\\theta_g}(\\boldsymbol{z})))]\n",
        "$$\n",
        "\n",
        "This translates into the following training loop pseudocode (taken form the [original GAN paper](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whyhr0NjyFWs"
      },
      "source": [
        "---\n",
        "### Algorithm 1: GAN training loop pseudocode\n",
        "---\n",
        "\n",
        " **for** number of training iterations **do**\n",
        "\n",
        "* **for** $k$ steps **do**\n",
        "* Sample minibatch of $m$ noise samples $\\{\\boldsymbol{z}^{(1)}, \\dotsc, \\boldsymbol{z}^{(m)}\\}$ from noise prior $p_g(\\boldsymbol{z})$\n",
        "* Sample minibatch of $m$ examples $\\{\\boldsymbol{x}^{(1)}, \\dotsc, \\boldsymbol{x}^{(m)}\\}$ from the data generating distribution $p_{\\text{data}}(\\boldsymbol{x})$\n",
        "* Update the discriminator by **ascending** its stochastic gradient:\n",
        "$$ \\nabla_{\\theta_{d}} \\frac{1}{m} \\sum_{i=1}^{m}\\left[\\log D\\left(\\boldsymbol{x}^{(i)}\\right)+\\log \\left(1-D\\circ G\\left(\\boldsymbol{z}^{(i)}\\right)\\right)\\right] $$\n",
        "* **end for**\n",
        "    * Sample minibatch of $m$ noise samples $\\{\\boldsymbol{z}^{(1)}, \\dotsc, \\boldsymbol{z}^{(m)}\\}$ from noise prior $p_g(\\boldsymbol{z})$\n",
        "    * Update the generator by **descending** its stochastic gradient:\n",
        "$$\\nabla_{\\theta_{g}} \\frac{1}{m} \\sum_{i=1}^{m} \\log \\left(1-D\\circ G\\left(\\boldsymbol{z}^{(i)}\\right)\\right)$$\n",
        "\n",
        " **end for**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaq_1zLHyOO6"
      },
      "source": [
        "What are we basically saying here? We will define some `training iterations` or `epochs` where we will loop through the training data and train our network. Our Discriminator $D$ will then be trained $k$ times for every time we train the Generator $G$. When we train one of the networks we keep the other fixed, that is, when we train the Discriminator, we keep the Generator fixed and vice versa. Note that some authors use $k=1$, but others have found that $k>1$ yields better results (see [WGAN](https://arxiv.org/abs/1701.07875))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FX3zHspRXvs"
      },
      "source": [
        "## A Heuristic\n",
        "\n",
        "However, there is a caveat noted in the original GAN paper and further discussed in the [NeurIPS 2016 Tutorial on GANs](https://arxiv.org/abs/1701.00160): we can see that at the beginning fo training, the distribution of the generated data will be *very* different to the real data, so the Discriminator will have an easy task as it won't have much problem distinguishing between the two of them. Therefore, $D\\circ G(z)$ will be small, and hence the signal for the Generator won't be enough to update its weights significantly. In other words, the minimax game **saturates** quickly, causing the gradients to **vanish**.\n",
        "\n",
        "To fix this, the authors propose the following change:\n",
        "\n",
        "$$\n",
        "\\min _{G} \\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z})))] = \\max_{G} \\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (D(G(\\boldsymbol{z})))]\n",
        "$$\n",
        "\n",
        "What we're looking to do is, instead of minimizing the likelihood of the Discriminator being correct, we will now aim to maximize the likelihood of the Discriminator being wrong. This has the same objective of fooling the Discriminator, but now the bad samples get a greater gradient feedback.\n",
        "\n",
        "Indeed, we can appreciate this whilst plotting both of the curves for the Generator loss $J^{(G)}$. Note that we are only interested in the <font color='blue'>blue</font> and <font color='green'>green</font> curves, as the former is our previous minimax formulation, while the latter is the heuristic we are applying. When $D\\circ G(z)$ is low, the heuristic will yield larger values, whereas the minimax formulation will have a low value.\n",
        "\n",
        "![Heuristic](https://user-images.githubusercontent.com/24496178/76852566-eb6f5780-684b-11ea-8b44-69aa8e0dbc31.png \"Heuristic\")\n",
        "[Image Source](https://arxiv.org/abs/1701.00160)\n",
        "\n",
        "We modify this in the pseudocode:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba6L0DvLyQJg"
      },
      "source": [
        "---\n",
        "### Algorithm 2: GAN training loop pseudocode with heuristic\n",
        "---\n",
        "**for** number of training iterations **do**\n",
        "\n",
        "   * **for** $k$ steps **do**\n",
        "        * Sample minibatch of $m$ noise samples $\\{\\boldsymbol{z}^{(1)}, \\dotsc, \\boldsymbol{z}^{(m)}\\}$ from noise prior $p_g(\\boldsymbol{z})$\n",
        "        * Sample minibatch of $m$ examples $\\{\\boldsymbol{x}^{(1)}, \\dotsc, \\boldsymbol{x}^{(m)}\\}$ from the data generating distribution $p_{\\text{data}}(\\boldsymbol{x})$\n",
        "        * Update the discriminator by **ascending** its stochastic gradient:\n",
        "        $$\n",
        "        \\nabla_{\\theta_{d}} \\frac{1}{m} \\sum_{i=1}^{m}\\left[\\log D\\left(\\boldsymbol{x}^{(i)}\\right)+\\log \\left(1-D\\circ G\\left(\\boldsymbol{z}^{(i)}\\right)\\right)\\right]\n",
        "        $$\n",
        "\n",
        "* **end for**\n",
        "    * Sample minibatch of $m$ noise samples $\\{\\boldsymbol{z}^{(1)}, \\dotsc, \\boldsymbol{z}^{(m)}\\}$ from noise prior $p_g(\\boldsymbol{z})$\n",
        "    * Update the generator by **ascending** its stochastic gradient:\n",
        "    $$\n",
        "    \\nabla_{\\theta_{g}} \\frac{1}{m} \\sum_{i=1}^{m} \\log D\\circ G\\left(\\boldsymbol{z}^{(i)}\\right)\n",
        "    $$\n",
        "\n",
        " **end for**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTsav0ZhWsCF"
      },
      "source": [
        "> In Either case, please note that we are only using the signal from the Discriminator to train both networks by using the Binary Crossentropy as previously discussed. The change will happen when we train the Generator, as we'll indicate that $y=1$ for the batch of fake data that it generates, but we will see that in the following section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JuhNcesqZYw"
      },
      "source": [
        "## Implementing the Training Loop\n",
        "\n",
        "We have all the components necessary to train our GAN, including the pseudocode, we just need to translate this into code!\n",
        "\n",
        "The core loop was adapted from `PyTorch`'s [DCGAN](https://arxiv.org/abs/1511.06434) [tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). After you've run and completed this notebook, I hope you can confidently go and test your understanding on said DCGAN tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MOpGsbrrDjg"
      },
      "source": [
        "But first, we will define two helper functions. First, a function taht we will be constantly calling in order to plot the distribution of our generated data, along with the distribution of the real data.\n",
        "\n",
        "In short, this function will plot the distribution of the generated `fake_data` along with that of the real `data` every `epoch`. No histogram will be plotted, just the `kde`. All plots will be saved at the `./animation` subdir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5ouadLT_lbX"
      },
      "outputs": [],
      "source": [
        "def plot_distribution(data: torch.Tensor,\n",
        "                      fake_data: torch.Tensor,\n",
        "                      epoch: int,\n",
        "                      hist: bool = False,\n",
        "                      kde: bool = True,\n",
        "                      figsize: Tuple[int] = (8, 6),\n",
        "                      root: Union[str, os.PathLike] = os.path.join(os.getcwd(), 'animation')) -> None:\n",
        "    \"\"\"Plot the real and fake data distributions at a specific epoch and save the figures at the `root` directory.\"\"\"\n",
        "    fig= plt.figure(figsize=figsize)\n",
        "    # Some values for the histogram are selected, should you choose to plot it:\n",
        "    sns.distplot(fake_data, hist=hist,  norm_hist=True, bins=50, rug=True, kde=kde,\n",
        "                 label='Generated Data Distribution', color=\"g\", rug_kws={\"alpha\": 0.1})\n",
        "    # We will compare it to the original data distribution:\n",
        "    sns.distplot(data, hist=False,  label='Real Data',\n",
        "                 kde_kws={'linestyle':'--', 'color': 'k'})\n",
        "    plt.title(f\"Generated Data Distribution - Epoch {epoch}\")\n",
        "    # Some of the limits will be dependent on the actual data:\n",
        "    plt.ylim((0, 1.5))\n",
        "    plt.xlim((actual_mean - 4.0, actual_mean + 4.0)) # pure heuristics on my part\n",
        "    # If the save path (root) doesn't exist, create it:\n",
        "    if not os.path.exists(root):\n",
        "        os.mkdir(root)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    # Save the plot of the distribution at that epoch:\n",
        "    save_name = os.path.join(root, f'g_distr_epoch{epoch:03d}.png')\n",
        "    plt.savefig(save_name)\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgZu-eytt3TD"
      },
      "source": [
        "During training, we will be calculating the runtime after each batch, so we have to format what [`time.time()`](https://docs.python.org/3/library/time.html#time.time) prints normally. The second helper function `format_time` will then format our runtime to a more human-readable string. Of course this is not necessary, especially since each time you fully train your network will take less than a minute, so\n",
        "\n",
        "There is no need to understand the following cell code in depth, just have it clear that it takes a time in seconds such as `80` or `80.0` (an `int` or `float`, hence `Union`) and returns a human-readable string, in this case `1m 20s`. This function is adapted from [here](https://github.com/NVlabs/stylegan2/blob/4874628c7dfffaae01f89558c476842b475f54d5/dnnlib/util.py#L111)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ioe7XF7ytnsU"
      },
      "outputs": [],
      "source": [
        "def format_time(seconds: Union[int, float]) -> str:\n",
        "    \"\"\"Convert the seconds to human readable string with days, hours, minutes and seconds.\"\"\"\n",
        "    s = int(np.rint(seconds))\n",
        "    if s < 60:\n",
        "        return f'{s}s'\n",
        "    elif s < 60 * 60:\n",
        "        return f'{s//60}m {s%60}s'\n",
        "    elif s < 24 * 60 * 60:\n",
        "        return f'{s // (60 * 60)}h {(s // 60) % 60}m {s%60}s'\n",
        "    else:\n",
        "        return f'{s // (24 * 60 * 60)}d {(s // (60 * 60)) % 24}h {(s // 60) % 60}m'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-GnZXhWaWVF"
      },
      "source": [
        "Ok then, we are done setting up everything, let's code the training loop pseudocode. We will have the following arguments:\n",
        "* `num_epochs`: the number of epochs to train our GAN\n",
        "* `lr`: the learning rate for both the Generator and Discriminator; you are free to modify this and have a different learning rate for each network\n",
        "* `num_eval`: denotes how often we print the message status of our training. Note that this number is dependent on how many minibatches you have (per epoch).\n",
        "* `data`, `hist`, `kde`, `root`: to be used as arguments for plotting the distribution with the function `plot_distribution` above\n",
        "* `d_repeats`: how many times to train $D$ compared to the times we train $G$, or $k$ in the pseudocode above. Instead, what I did here was that we train $G$ every `d_repeats`, which will yield the results we are seeking.\n",
        "\n",
        "We will be translating the Algorithm 2 from pseudocode to code now, so make sure to go back and forth in order to better understand what is happening:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBsv_0RpxuXl"
      },
      "outputs": [],
      "source": [
        "def train(num_epochs: int = 50,\n",
        "          lr: float = 1e-4,\n",
        "          num_eval: int = 1,\n",
        "          data: torch.Tensor = data,\n",
        "          hist: bool = True,\n",
        "          kde: bool = False,\n",
        "          d_repeats: int = 1,\n",
        "          root: Union[str, os.PathLike] = os.path.join(os.getcwd(), 'animation')):\n",
        "    \"\"\" Train the Generator and Discriminator for the given amount of epochs. \"\"\"\n",
        "    # Some sanity check:\n",
        "    wow = \"Epochs must be at least 1 and an int!\"\n",
        "    assert num_epochs > 0 and isinstance(num_epochs, int), wow\n",
        "\n",
        "    # We will use Adam for both optimizers with same learning rate:\n",
        "    optimizerD = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "    optimizerG = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "    # We will keep track of the generator and discriminator losses:\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "\n",
        "    # We will log the generated fake data (with the fixed_latent) in order to\n",
        "    # track our progression throughout training (i.e., plot it later on):\n",
        "    fake_data = []\n",
        "\n",
        "    # This will remove the previous run subdir (should this be the second time\n",
        "    # you run this code; make sure to save the previous run if you so wish):\n",
        "    shutil.rmtree(root, ignore_errors=True)\n",
        "\n",
        "    # Mark the beginning of training time:\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(\"***** Starting training *****\")\n",
        "    for epoch in range(num_epochs):\n",
        "        # For each batch in our dataloader:\n",
        "        for i, d in enumerate(dataloader):\n",
        "            ############################################\n",
        "            #                  a.              b.\n",
        "            # Update D: max log(D(x)) + log(1 - D(G(z)))\n",
        "            ############################################\n",
        "            ### a. Train D with a real batch. First zero_grad the optimizer:\n",
        "            optimizerD.zero_grad()\n",
        "            # Move the batch data to the device:\n",
        "            real_b = d.to(device)\n",
        "            # We want the batch size to create the labels and latent vectors\n",
        "            # later on (remember the last batch won't be of size 1024):\n",
        "            b_size = real_b.size(0)\n",
        "            # Label of real data:\n",
        "            label = torch.full((b_size, ),\n",
        "                               real_label, # we fill it with ones\n",
        "                               device=device)\n",
        "            # Classify the real batch with D:digits_total_iters\n",
        "            output = discriminator(real_b).view(-1)\n",
        "            # Calculate the loss on this real batch:\n",
        "            err_D_real = criterion(output, label)\n",
        "            # Calculate the gradients for D in backward pass:\n",
        "            err_D_real.backward()\n",
        "            # We calculate the average classification of the real data to monitor\n",
        "            # its progression (should start high, then get lower)\n",
        "            D_X = output.mean().item()\n",
        "\n",
        "            ### b. Train D with a fake batch:\n",
        "            # Generate a batch of latent vectors:\n",
        "            latents = get_latents(N=b_size,\n",
        "                                  latent_dim=latent_dim)\n",
        "            # Generate fake data with G:\n",
        "            fake_b = generator(latents).to(device)\n",
        "            # Let's reuse label (hence in-place fill) by filling with 0's:\n",
        "            label.fill_(fake_label)\n",
        "            # Classify the fake batch with D:\n",
        "            output = discriminator(fake_b.detach()).view(-1)\n",
        "            # Calculate D's loss on this fake batch:\n",
        "            err_D_fake = criterion(output, label)\n",
        "            # Calculate the gradients for D in backward pass:\n",
        "            err_D_fake.backward()\n",
        "            # We calculate the average classification of the fake data to monitor\n",
        "            # its progression:\n",
        "            D_G_z = output.mean().item()\n",
        "\n",
        "            # Add both gradients from the all-real and all-fake batches:\n",
        "            err_D = err_D_real + err_D_fake\n",
        "            # Once we've accumulated both gradients in the backward pass, we take\n",
        "            # a step:\n",
        "            optimizerD.step()\n",
        "\n",
        "            # Now on to train the Generator: remember we are in essence training\n",
        "            # D d_repeats every time we train G one time\n",
        "            if i % d_repeats == 0:\n",
        "                ##############################\n",
        "                #                   c.\n",
        "                # Update G: max log(D(G(z)))\n",
        "                ##############################\n",
        "                ## c. Train G with a fake batch:\n",
        "                optimizerG.zero_grad()\n",
        "                # This time, for the Generator, we fill the label with 1's:\n",
        "                label.fill_(real_label)\n",
        "                # We updated D before this, so we make another forward-pass of an\n",
        "                # all-fake batch:\n",
        "                output = discriminator(fake_b).view(-1)\n",
        "                # Calculate G's loss based on this output:\n",
        "                err_G = criterion(output, label)\n",
        "                # Calculate the gradient for G:\n",
        "                err_G.backward()\n",
        "                # Update G:\n",
        "                optimizerG.step()\n",
        "\n",
        "            #######################################################################\n",
        "            # That's it for Algorithm 2; now on to printing some summary statistics\n",
        "            #######################################################################\n",
        "\n",
        "            # I am an order maniac, so I wish to print the number of necessary\n",
        "            # spaces depending on the number of digits for epochs and batches:\n",
        "            epoch_digits = int(np.log10(num_epochs)) + 1\n",
        "            batch_digits = int(np.log10(len(dataloader))) + 1\n",
        "            # Print our training statistics every num_eval:\n",
        "            if i % num_eval == 0:\n",
        "                # Get the current time:\n",
        "                runtime = time.time() - start_time\n",
        "                # Our code will run in much less than 1 hour, so we really only\n",
        "                # need space for 6 strings for the runtime (hence %-6s):\n",
        "                log_console = (\"\\r[%{}d/%{}d][%{}d/%{}d]  Runtime: %-6s  Loss_D: %.4f\"\n",
        "                \"  Loss_G: %.4f  D(x): %.4f  D(G(z)): %.4f\").format(*2*[epoch_digits], *2*[batch_digits])\n",
        "                # Print it:\n",
        "                print(log_console % (epoch, num_epochs, i, len(dataloader), format_time(runtime),\n",
        "                                     err_D.item(), err_G.item(), D_X, D_G_z))\n",
        "\n",
        "        # After every epoch, we save the losses:\n",
        "        G_losses.append(err_G.item())\n",
        "        D_losses.append(err_D.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on the fixed_latent\n",
        "        with torch.no_grad():\n",
        "            fake_X = generator(fixed_latent).detach().cpu()\n",
        "        fake_data.append(fake_X)\n",
        "        # Let's plot this fake data distribution and save it:\n",
        "        plot_distribution(data,\n",
        "                          fake_X,\n",
        "                          epoch,\n",
        "                          hist=hist,\n",
        "                          kde=kde,\n",
        "                          root=root)\n",
        "    print(\"\\n***** Finished training *****\")\n",
        "\n",
        "    # Return both losses for the Generator and Discriminator, as well as the\n",
        "    # fake data generated with our fixed_latent\n",
        "    return G_losses, D_losses, fake_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUWTwm5jXgbD"
      },
      "source": [
        "> We have made it so that the training loop will return the generated data, `fake_data`, but in the grand scheme of things, perhaps it would be best to save this fake data to a file so that then it can be loaded. This won't be necessary for our present case, as the generated data is of small size and can be stored into the variable `fake_data` without having us worry about running out of memory.\n",
        "\n",
        "> Likewise, it is not unusual to save the models every $n$ batches or iterations in our training loop, but since this problem won't take long to train, this won't be necessary. Keep this in mind for future training loops for more complex models you might have in mind. Or, should the model be simple, then for more complex datasets, as each batch might take too many resources.\n",
        "\n",
        "We'll train the for `70` epochs and, according to [the Law](https://twitter.com/karpathy/status/801621764144971776) we'll set `lr=3e-4` (make sure to read the second tweet). We'll also print our statistics every `4` batches, and train our Generator the same number of times that we train our Discriminator, that is, `d_repeats=1`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRhDKQSsWTc-",
        "outputId": "9b53595e-be0d-4f06-b646-97f308ff6256"
      },
      "outputs": [],
      "source": [
        "G_losses, D_losses, fake_data = train(num_epochs=100,\n",
        "                                      lr=3e-4,\n",
        "                                      num_eval=4,\n",
        "                                      data=data,\n",
        "                                      hist=False,\n",
        "                                      kde=True,\n",
        "                                      d_repeats=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SbijAkQEbZZ"
      },
      "source": [
        "Note that $D(x)$ starts near $1$ and ends up near $1/2$, and that $D(G(z))$ starts a bit higher than $1/2$, then gets lower, then ends up near $1/2$. This is exactly what we wish to accomplish, but have we really achieved $p_g = p_\\text{data}$? We'll soon find out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl5ZjyQGEBRT"
      },
      "source": [
        "## Plotting the Losses\n",
        "\n",
        "Training is done, we can now plot the losses of both the Discriminator and the Generator. In order to understand these plots, recall that when we've successfully trained our GAN, $D^{*}(x)=1/2$, for any input $x$. Replacing this into the respective losses for each network, we obtain that the 'optimal' value for the losses will be, respectively for the Discriminator and Generator:\n",
        "\n",
        "$$ J^{(D^*)} = - (\\log{D^*(x)} + \\log{(1-D^*(G(z)))}) = - (\\log{(1/2)} + \\log{(1-1/2)})=2\\log 2 = \\log 4 $$\n",
        "\n",
        "$$ J^{(G)} = - \\log{D^*(G(z))} =  - \\log{(1/2)}=\\log 2 $$\n",
        "\n",
        "Let's plot the losses then and see how they compare to these values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "0vWkIOOlX37D",
        "outputId": "3bfc0fff-b573-4a02-a5ca-9c642b997d0a"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "plt.plot(D_losses, label=\"Discriminator loss\")\n",
        "plt.plot(G_losses, label=\"Generator loss\")\n",
        "ax.axhline(np.log(2), c='orange', ls='--', label='$\\log{2}$')\n",
        "ax.axhline(np.log(4), c='blue', ls='--', label='$\\log{4}$')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u_8miPtU7lY"
      },
      "source": [
        "Apparently, they've stabilized around the desired optimal value! Does this mean that our network has converged to a *meaningful* solution, and that the generated data is indeed similar to the actual data?\n",
        "\n",
        "Short answer: No. Long answer: ***also No, but in bold***. Let us start by analyzing the `fake_data` that we have stored, by first calculating the mean and standard deviation at each epoch, and then plotting these against the real values we have stored at the beginning of our notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjePF5mraNpn"
      },
      "outputs": [],
      "source": [
        "means = [d.mean() for d in fake_data]\n",
        "stds = [d.std() for d in fake_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "tF6INImha4RH",
        "outputId": "fe72d88e-da04-4555-e621-67db993be968"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "plt.plot(means, label='Generated mean')\n",
        "ax.axhline(y=actual_mean, c='blue', ls='--', label=f'Actual mean: {actual_mean:.3f}')\n",
        "plt.plot(stds, label='Generated standard dev')\n",
        "ax.axhline(y=actual_std, c='orange', ls='--', label=f'Actual std dev: {actual_std:.3f}')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.title(f\"Final mean: {means[-1]:.3f}, Final std dev: {stds[-1]:.3f}\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Go-BOlardm"
      },
      "source": [
        "We can see that the mean is getting close to the `actual_mean`, but the values of the standard deviation aren't improving; indeed, they seem to be diverging from `actual_std`. In short, we haven't really obtained the actual distribution, as $p_{g}$ is still far away from $p_\\text{data}$, i.e., we've **failed to converge**. More on this can be read in Appendix B, though this effect is more drastic for images.\n",
        "\n",
        "As a conclusion, a higher/lower loss is not really correlated with the *quality* of our generated data. This was one of the reasons why [WGAN](https://arxiv.org/abs/1701.07875) was such an important paper, as they showed that their change in the loss function leads to a more intuitive correlation between the loss and image quality. I hope that you have the time to read it, should you have the time of course. Honestly, not many changes are needed in order to turn the GAN we have created above into a WGAN, but we will leave that for another time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw6Zc0Se-lCJ"
      },
      "source": [
        "# Results: Animating the Training\n",
        "\n",
        "Let's explore the fruits of our hard work in a more fun way. We can of course go to the `Files` on the left and inspect each individual disribution plot, or we can do something more interesting and make an animation with these files.\n",
        "\n",
        "We will use [`ffmpeg`](https://www.ffmpeg.org/) to grab all the training images in `./animation` in order to make a video of the training process and save it as `./training_video.mp4`. Perhaps the only parameter you can change is `-framerate 20`, as this will control the fps of the training video, so I leave this up to you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWJH-Sodnd-2"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -loglevel quiet -y -framerate 20 -i ./animation/g_distr_epoch%3d.png -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p training_video.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvcKhZXzohp6"
      },
      "source": [
        "`-loglevel quiet` will suppress the output, which can be quite wordy and uninteresting at times. However, don't use it when starting new projects, as the error outputs will not be uncommon.\n",
        "\n",
        "The `-y` flag at the beginning will simply overwrite any other file with the same name, which is useful if you run many times the above code when testing different parameters, hyperparameters, architectures, etc. Another option is for you to simply give different names to each training, but to each their own.\n",
        "\n",
        "To obtain a GIF, we can simply use this generated MP4 file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7JQQT9iohYt"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -loglevel quiet -y -i training_video.mp4 training_gif.gif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8YinMSXzHL0"
      },
      "source": [
        "If you do not wish to meddle too much with `ffmpeg` and prefer to remain in `Python`, you could also try installing [`ffmpeg-python`'](https://github.com/kkroening/ffmpeg-python) via `!pip install ffmpeg-python`. For example, to recreate the previous cell, you could change it to:\n",
        "\n",
        "```py\n",
        "import ffmpeg\n",
        "ffmpeg.input('training_video.mp4').output('training_gif.gif').run(capture_stdout=True, capture_stderr=True)\n",
        "```\n",
        "\n",
        "In either case, we can then download the generated video or GIF to our local machine to watch it, or simply display it in the notebook like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "IsuZ4MJaxRFG",
        "outputId": "970890a4-5b4b-497b-cb75-5c9cc08b178d"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "with open('./training_gif.gif', 'rb') as f:\n",
        "    display(Image(data=f.read(), format='png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAs0we5_Pgu"
      },
      "source": [
        "We can see in a more visual way what we already plotted and discussed above: the mean of the generated data is getting closer to the real one, but the standard deviation is actually increasing. Bad news! We need better hyperparameters in order to successfully mimic the real data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SluBEA3znYkj"
      },
      "source": [
        "> Now, you can find in the `Files` menu to the left the relevant images, video and GIF. Save whichever you wish to save to your local machine, or upload to your Google Drive via running in a cell:\n",
        " ```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "```\n",
        "or simply click the button **Mount Drive** on the top left. For more steps regarding mounting Google Drive on Colab, follow [this guide](https://medium.com/@ml_kid/how-to-save-our-model-to-google-drive-and-reuse-it-2c1028058cb2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A-wcJ45av4o"
      },
      "source": [
        "## Saving and Loading the Models\n",
        "\n",
        "Of course, assuming we are satisfied with our training, we can just save our models like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xleyTzH2aWyF"
      },
      "outputs": [],
      "source": [
        "torch.save(generator.state_dict(), './trained_g.pth')\n",
        "torch.save(discriminator.state_dict(), './trained_d.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TGF9PaVd-nf"
      },
      "source": [
        "It is best to save the model's `state_dict()` instead of the entire model, as per `PyTorch`'s [best practices](https://pytorch.org/docs/stable/notes/serialization.html).\n",
        "\n",
        "To resume from this checkpoint in order to continue training or generate new values, we can load each model like so (note that `hidden_dim` must match to the one you had in your saved `.pth` file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfByxdYPa0or",
        "outputId": "bb51d5c9-a0c4-4ac0-d984-f4e593d9ff1a"
      },
      "outputs": [],
      "source": [
        "g = Generator(hidden_dim=15)\n",
        "g.load_state_dict(torch.load('./trained_g.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg9fnLaJb2fa",
        "outputId": "86283104-93dd-4c54-cabd-cf18da1a21a4"
      },
      "outputs": [],
      "source": [
        "d = Discriminator(hidden_dim=25)\n",
        "d.load_state_dict(torch.load('./trained_d.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkL9_NFJcd4_"
      },
      "source": [
        "For a more detailed review on this subject, [follow this tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvE1bW_Hbyvv"
      },
      "source": [
        "# **Tasks**\n",
        "\n",
        "***Work in groups of up to 3 students***\n",
        "***Deadline: May 12nd at midnight.***\n",
        "\n",
        "For the following, **make sure you are starting with an untrained Generator and Discriminator**. One way to do this is to run all the cells from the top or, when in doubt, restart the kernel altogether. Each exercise is worth 0.25 points.\n",
        "\n",
        "1. Imagine you have a dataset $\\mathcal{X}$ that you wish to generate *new* samples from. Explain *why* you would choose a GAN over any other type of generative network for this task. Be as specific or as general as you want. For example, if your data is extremely multimodal, would a GAN be the right choice? What if sampling speed was a major constraint? Or if there are concerns regarding the data privacy once you have a trained model? Let your imagination run wild.\n",
        "\n",
        "2. Clearly, the training we've done above has failed to replicate $p_\\text{data}$ (for the Normal distribution). But we're not interested in this easy dataset, we are interested in one of the *harder* distributions found below (`Laplacian`, `HalfNormal`, `PetitPrince`). Choose ***one***, use the generated `data` found below each, and determine the set of parameters and hyperparameters that will make it easier for our network to approximate $p_\\text{data}$.\n",
        "\n",
        "> *Note*: For some of these distributions, there is a **theoretical** value for the mean and standard deviation. You can calculate these values and use them in your trials in order to ensure you are indeed converging to the desired distribution.\n",
        "\n",
        "In your report, I expect you try variations in **at least** the following parameters/hyperparameters:\n",
        " * The number of epochs\n",
        " * The latent space dimension $|\\mathcal{Z}|$. Above, we used 5-dim, perhaps a different value will be more useful.\n",
        "    > *Note*: [StyleGAN](https://github.com/NVlabs/stylegan)/[StyleGAN2](https://github.com/NVlabs/stylegan2)/[StyleGAN3](https://github.com/NVlabs/stylegan3) have latent spaces with size $|\\mathcal{Z}|=512$, whereas the much-larger [StyleGAN-XL](https://sites.google.com/view/stylegan-xl/) has $|\\mathcal{Z}|=64$, so don't go too crazy.\n",
        " * Generator and Discriminator capacity (number of layers and/or hidden neurons)\n",
        "    > *Clue*: Do you think it's benefitial for the generator $G$ if the discriminator $D$ is always *stronger* (i.e., more hidden layers, more neurons per layer, more complex architecture, etc.) when compared to $G$? What do your experiments tell you?\n",
        " * How many times you train the Discriminator vs how many times you train the Generator per epoch: `d_repeats`.\n",
        " * All the optimization parameters (learning rate, batch size, etc.)\n",
        "\n",
        " Report all trials you perform in the form of graphs, training GIF, final plot of the distribution, however you so choose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJyvRBOdMH4o"
      },
      "source": [
        "## Harder Distributions - One-Dimensional Data\n",
        "\n",
        "### [Laplace Distribution](https://en.wikipedia.org/wiki/Laplace_distribution) $p_{\\text{data}}=\\text{Laplace}(\\mu, b)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSZeqVuxGcnc"
      },
      "outputs": [],
      "source": [
        "class LaplaceDistribution:\n",
        "    def __init__(self, loc: float = 3.0, scale: float = 0.3):\n",
        "        self.loc = torch.tensor([loc])\n",
        "        self.scale = torch.tensor([scale])\n",
        "\n",
        "    def sample(self, N: int = None, seed: int = 42):\n",
        "        # Set the seed for reproducibility:\n",
        "        torch.manual_seed(seed)\n",
        "        m = torch.distributions.Laplace(loc=self.loc, scale=self.scale)\n",
        "        N = 1 if N is None else N\n",
        "        samples = m.sample([N])\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Appqt7exG9Yx"
      },
      "outputs": [],
      "source": [
        "data = LaplaceDistribution(loc=3.0, scale=0.3).sample(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "pREtYxSCHLH3",
        "outputId": "83c35348-9a25-4f11-e62f-75a2953e5696"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.distplot(data, kde=False, rug=True, bins=150,\n",
        "             norm_hist=True, hist_kws={'color': 'red'},\n",
        "             rug_kws={'alpha': 0.05, 'color': 'navy'})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2cLMkUZ-qM4"
      },
      "source": [
        "### [Half Normal Distribution](https://en.wikipedia.org/wiki/Half-normal_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stOLYrbeAbhy"
      },
      "outputs": [],
      "source": [
        "class HalfNormalDistribution:\n",
        "    def __init__(self, scale: float = 0.75):\n",
        "        self.scale = torch.tensor([scale])\n",
        "\n",
        "    def sample(self, N: int = None, seed: int = 42):\n",
        "        # Set the seed for reproducibility:\n",
        "        torch.manual_seed(seed)\n",
        "        m = torch.distributions.HalfNormal(scale=self.scale)\n",
        "        N = 1 if N is None else N\n",
        "        samples = m.sample([N])\n",
        "\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ9nAqzxAfqe"
      },
      "outputs": [],
      "source": [
        "data = HalfNormalDistribution(scale=0.75).sample(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "AxchDcBDAhvk",
        "outputId": "5cb6552d-22a9-429a-c1b4-c3a0ed2517ac"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.distplot(data, kde=False, rug=True, bins=100,\n",
        "             norm_hist=True, hist_kws={'color': 'darkgreen'},\n",
        "             rug_kws={'alpha': 0.05, 'color': 'purple'})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHjcwblPrGqS"
      },
      "source": [
        "### [Petit Prince Distribution](https://66.media.tumblr.com/tumblr_lzf2o3epcz1qkww7to1_400.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MewspOins62"
      },
      "outputs": [],
      "source": [
        "class PetitPrinceDistribution:\n",
        "    def __init__(self, mu1: float = 4.0, sigma1: float = 1.5, mu2: float = 0.6, sigma2: float = 1.35):\n",
        "        self.mu1 = torch.tensor([mu1])\n",
        "        self.sigma1 = torch.tensor([sigma1])\n",
        "        self.mu2 = torch.tensor([mu2])\n",
        "        self.sigma2 = torch.tensor([sigma2])\n",
        "\n",
        "    def sample(self, N: int = None, seed: int = 42):\n",
        "        # Set the seed for reproducibility:\n",
        "        torch.manual_seed(seed)\n",
        "        # Define the distribution:\n",
        "        m1 = torch.distributions.normal.Normal(loc=self.mu1, scale=self.sigma1)\n",
        "        m2 = torch.distributions.normal.Normal(loc=self.mu2, scale=self.sigma2)\n",
        "        N = 1 if N is None else N\n",
        "        samples = torch.cat((m1.sample([N//2]), m2.sample([N-N//2])), 0)\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C_92GHQoMIS"
      },
      "outputs": [],
      "source": [
        "data = PetitPrinceDistribution().sample(N=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "kE02dCAZpQut",
        "outputId": "56646392-5dc0-48b6-d568-1746f9ccea79"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.distplot(data, norm_hist=True, rug=True, bins=50,\n",
        "             kde_kws={'color': 'k', 'linewidth': 3},\n",
        "             hist_kws={'color': 'chocolate'},\n",
        "             rug_kws={'alpha': 0.05, 'color': 'k'})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ddhl9a5eyl_"
      },
      "source": [
        "## Harder Distributions - Two-Dimensional Data\n",
        "\n",
        "These are my latest additions, but feel free to use them with or without classes. You might need to fix some of the previous code for plotting statistics, but it shouldn't be hard to do this (and you can just focus on the generated data at each step if you choose one of the following datasets).\n",
        "\n",
        "Please note that it'd be best to save the data you use with whichever random seed you select so that you can reproduce things later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K2f-Y-Egz9K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple, Union\n",
        "import os\n",
        "import abc\n",
        "\n",
        "\n",
        "class TwoDimensionalDataset(abc.ABC):\n",
        "    def __init__(self, num_groups: int = 2, points_per_group: int = 2, labeled: bool = True, seed: int = 0):\n",
        "        self.num_groups = num_groups                # How many groups in the data\n",
        "        self.points_per_group = points_per_group    # How many datapoints in each group\n",
        "        self.data = None                            # Save the generated data\n",
        "        self.labels = None                          # Save the labels, if they exist\n",
        "        self.labeled = labeled                      # Conditional or unconditional data\n",
        "        self.data_type = 'Generic'                  # Type of the data\n",
        "        self.seed = seed                            # Random seed used\n",
        "        self.rnd = np.random.RandomState(seed=seed) # Set the random state seed\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def generate_data(self):\n",
        "        \"\"\" Method to generate the dataset. \"\"\"\n",
        "        pass\n",
        "\n",
        "    def plot_data(self, save_plot: bool = False, save_dir: Union[str, os.PathLike] = 'plots', additional_desc: str = '') -> None:\n",
        "        if self.data is not None:\n",
        "            plt.scatter(self.data[:, 0], self.data[:, 1],\n",
        "                        c=self.labels, cmap='viridis' if self.labeled else None)\n",
        "            plt.title(f'2D Data of type: {self.data_type}')\n",
        "            plt.xlabel('X-axis')\n",
        "            plt.ylabel('Y-axis')\n",
        "            plt.show()\n",
        "\n",
        "            if save_plot:\n",
        "                # Ensure the save directory exists\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "                # Construct file name\n",
        "                labeled_str = 'labeled' if self.labeled else 'unlabeled'\n",
        "                file_name = f'{self.data_type.replace(\" \", \"\")}_{self.num_groups:02d}groups'\n",
        "                file_name = f'{file_name}_{self.points_per_group:04d}points'\n",
        "                file_name = f'{file_name}_{additional_desc}' if len(additional_desc) != 0 else file_name\n",
        "                file_name = f'{file_name}_{labeled_str}.jpg'\n",
        "                file_path = os.path.join(save_dir, file_name)\n",
        "                plt.savefig(file_path)\n",
        "                print(f'Plot saved to: {file_path}')\n",
        "            plt.close()\n",
        "        else:\n",
        "            print('No data has been generated!')\n",
        "\n",
        "    def save_data(self, save_dir: Union[str, os.PathLike] = 'datasets',\n",
        "                  file_name: str = None, additional_desc: str = '') -> None:\n",
        "        if self.data is not None:\n",
        "            # Ensure the save directory exists\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "            # Construct the file name if not provided\n",
        "            if not file_name:\n",
        "                labeled_str = 'labeled' if self.labeled else 'unlabeled'\n",
        "                file_name = f'{self.data_type.replace(\" \", \"\")}_{self.num_groups:02d}groups'\n",
        "                file_name = f'{file_name}_{self.points_per_group:04d}points_{labeled_str}'\n",
        "                file_name = f'{file_name}_{additional_desc}' if len(additional_desc) != 0 else file_name\n",
        "                file_name = f'{file_name}.npy'\n",
        "\n",
        "            # Sanity check\n",
        "            if not file_name.endswith('.npy'):\n",
        "                file_name = f'{file_name}.npy'\n",
        "            file_path = os.path.join(save_dir, file_name)\n",
        "\n",
        "            # Save the data and labels in a dictionary\n",
        "            data_dict = {'data': self.data, 'labels': self.labels}\n",
        "            np.save(file_path, data_dict)\n",
        "            print(f\"Data saved to {file_path}\")\n",
        "        else:\n",
        "            print('No data has been generated!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilgAObr3g6s7"
      },
      "source": [
        "### Gaussians on Circle\n",
        "\n",
        "Generate Gaussian clusters that lie on a circle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhpM_cNZhBsb"
      },
      "outputs": [],
      "source": [
        "class GaussiansOnCircleDataset(TwoDimensionalDataset):\n",
        "    def __init__(self, num_groups: int = 3, points_per_group: int = 100, std_dev: float = 0.1,\n",
        "                 circle_radius: float = 1.0, labeled: bool = True, seed: int = 0):\n",
        "        super().__init__(num_groups, points_per_group, labeled)\n",
        "        self.std_dev = std_dev\n",
        "        self.circle_radius = circle_radius\n",
        "        self.data_type = 'GaussiansOnCircle'\n",
        "        self.additional_description = f\"radius{self.circle_radius:2.3f}_stddev{self.std_dev:2.3f}\"\n",
        "        self.seed = seed\n",
        "        self.rnd = np.random.RandomState(seed=seed)\n",
        "\n",
        "    def generate_data(self) -> None:\n",
        "        data = []\n",
        "        labels = [] if self.labeled else None\n",
        "        angle_step = 2 * np.pi / self.num_groups\n",
        "        for i in range(self.num_groups):\n",
        "            angle = i * angle_step\n",
        "            center = np.array([np.cos(angle), np.sin(angle)]) * self.circle_radius\n",
        "            cluster_data = self.rnd.randn(self.points_per_group, 2) * self.std_dev + center\n",
        "            data.append(cluster_data)\n",
        "            if self.labeled:\n",
        "                labels.append(np.full(self.points_per_group, i))\n",
        "        self.data = np.vstack(data)\n",
        "        self.labels = np.concatenate(labels) if self.labeled else None\n",
        "\n",
        "    def plot_data(self, save_plot: bool = False, save_dir: Union[str, os.PathLike] = 'plots', additional_desc: str = '') -> None:\n",
        "        \"\"\" Pass additional description of this class when plotting (standard deviation and radius of circle) \"\"\"\n",
        "        super().plot_data(save_plot=save_plot, additional_desc=additional_desc)\n",
        "\n",
        "    def save_data(self, save_dir: Union[str, os.PathLike] = 'datasets', file_name: str = None,\n",
        "                  additional_desc: str = ''):\n",
        "        \"\"\" Pass additional description of this class when saving the data (standard deviation and radius of circle) \"\"\"\n",
        "        super().save_data(additional_desc=additional_desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Rpg0I-MOpiwp",
        "outputId": "8e4591e8-c6e8-48ca-bf80-5170a5ccbab7"
      },
      "outputs": [],
      "source": [
        "# Generate *unlabeled* data with a chosen random seed\n",
        "dataset = GaussiansOnCircleDataset(\n",
        "    num_groups=5, points_per_group=1000, labeled=False, seed=1000)\n",
        "\n",
        "dataset.generate_data()\n",
        "# Plot it\n",
        "dataset.plot_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Dv1Ewvz0hDGG",
        "outputId": "8a4d2273-e2d4-4316-c161-adfa6da49f2b"
      },
      "outputs": [],
      "source": [
        "# Generate labeled data\n",
        "dataset = GaussiansOnCircleDataset(\n",
        "    num_groups=5, points_per_group=1000, labeled=True, seed=1000)\n",
        "\n",
        "dataset.generate_data()\n",
        "# Plot it\n",
        "dataset.plot_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ws4JmCTsYSN",
        "outputId": "99493018-b539-4126-bc20-1045851e98f9"
      },
      "outputs": [],
      "source": [
        "# The data will be then the XY position of each and labels is an int\n",
        "dataset.data, dataset.labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXHHzWDxf54N"
      },
      "source": [
        "### Spirals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goEEhTF0jP3V"
      },
      "outputs": [],
      "source": [
        "class SpiralsDataset(TwoDimensionalDataset):\n",
        "    def __init__(self, num_groups: int = 2, points_per_group: int = 1000, labeled: bool = True):\n",
        "        super().__init__(num_groups, points_per_group, labeled)\n",
        "        self.data_type = \"Spirals\"\n",
        "\n",
        "    def generate_data(self) -> None:\n",
        "        data = []\n",
        "        labels = [] if self.labeled else None\n",
        "        theta = np.linspace(0, 2 * np.pi, self.points_per_group)\n",
        "        r = np.linspace(0, 10, self.points_per_group)\n",
        "        for i in range(self.num_groups):\n",
        "            x = r * np.cos(theta + i * np.pi / self.num_groups)\n",
        "            y = r * np.sin(theta + i * np.pi / self.num_groups)\n",
        "            spiral_data = np.stack([x, y], axis=1)\n",
        "            data.append(spiral_data)\n",
        "            if self.labeled:\n",
        "                labels.append(np.full(self.points_per_group, i))\n",
        "        self.data = np.vstack(data)\n",
        "        self.labels = np.concatenate(labels) if self.labeled else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "m78nkXefjUCd",
        "outputId": "48c96035-ab50-46e2-998a-bf9c6e74aa51"
      },
      "outputs": [],
      "source": [
        "# Generate it\n",
        "dataset = SpiralsDataset(\n",
        "    num_groups=5, points_per_group=200, labeled=True)\n",
        "\n",
        "dataset.generate_data()\n",
        "# Plot it\n",
        "dataset.plot_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQRjnEn0ks5G"
      },
      "source": [
        "### Interlocking Spirals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98fFtfnwku1W"
      },
      "outputs": [],
      "source": [
        "class InterlockingSpiralsDataset(TwoDimensionalDataset):\n",
        "    def __init__(self, num_groups: int = 2, points_per_group: int = 1000, labeled: bool = True, seed: int = 0):\n",
        "        super().__init__(num_groups, points_per_group, labeled)\n",
        "        self.data_type = \"InterlockingSpirals\"\n",
        "        self.seed = seed\n",
        "        self.rnd = np.random.RandomState(seed=seed)\n",
        "\n",
        "    def generate_data(self):\n",
        "        data = []\n",
        "        labels = [] if self.labeled else None\n",
        "        theta = np.linspace(0, 2 * np.pi, self.points_per_group)\n",
        "        for i in range(self.num_groups):\n",
        "            r = theta + self.rnd.randn(self.points_per_group) * 0.1\n",
        "            x = r * np.cos(theta + i * np.pi / self.num_groups)\n",
        "            y = r * np.sin(theta + i * np.pi / self.num_groups)\n",
        "            spiral_data = np.stack([x, y], axis=1)\n",
        "            data.append(spiral_data)\n",
        "            if self.labeled:\n",
        "                labels.append(np.full(self.points_per_group, i))\n",
        "        self.data = np.vstack(data)\n",
        "        self.labels = np.concatenate(labels) if self.labeled else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "U9TuaDd_kyum",
        "outputId": "ffb99985-ab23-4c9a-8976-48521ad58946"
      },
      "outputs": [],
      "source": [
        "# Generate it\n",
        "dataset = InterlockingSpiralsDataset(\n",
        "    num_groups=5, points_per_group=200, labeled=True, seed=1000)\n",
        "\n",
        "dataset.generate_data()\n",
        "# Plot it\n",
        "dataset.plot_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB0sEj9ef8zU"
      },
      "source": [
        "### Concentric Circles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE0rOIV3lbtH"
      },
      "outputs": [],
      "source": [
        "class ConcentricCirclesDataset(TwoDimensionalDataset):\n",
        "    def __init__(self, num_groups: int = 3, points_per_group: int = 100, labeled: bool = True, seed: int = 0):\n",
        "        super().__init__(num_groups, points_per_group, labeled)\n",
        "        self.data_type = \"ConcentricCircles\"\n",
        "        self.seed = seed\n",
        "        self.rnd = np.random.RandomState(seed=seed)\n",
        "\n",
        "    def generate_data(self):\n",
        "        data = []\n",
        "        labels = [] if self.labeled else None\n",
        "        for i in range(self.num_groups):\n",
        "            radius = 1 + i * 0.5\n",
        "            theta = np.linspace(0, 2 * np.pi, self.points_per_group)\n",
        "            x = radius * np.cos(theta) + self.rnd.randn(self.points_per_group) * 0.1\n",
        "            y = radius * np.sin(theta) + self.rnd.randn(self.points_per_group) * 0.1\n",
        "            circle_data = np.stack([x, y], axis=1)\n",
        "            data.append(circle_data)\n",
        "            if self.labeled:\n",
        "                labels.append(np.full(self.points_per_group, i))\n",
        "        self.data = np.vstack(data)\n",
        "        self.labels = np.concatenate(labels) if self.labeled else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "4AdRkr7jld8V",
        "outputId": "c8777503-7fef-4c31-abf6-e61aedcc5dfc"
      },
      "outputs": [],
      "source": [
        "# Generate it\n",
        "dataset = ConcentricCirclesDataset(\n",
        "    num_groups=5, points_per_group=200, labeled=True)\n",
        "\n",
        "dataset.generate_data()\n",
        "# Plot it\n",
        "dataset.plot_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4A0jLZbf_dL"
      },
      "source": [
        "### Swiss Roll with Holes\n",
        "\n",
        "ChatGPT proposal, I might've vibe-coded too close to the Sun with this one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPkxY6p-mhHK"
      },
      "outputs": [],
      "source": [
        "class SwissRollDataset(TwoDimensionalDataset):\n",
        "    def __init__(self, points_per_group: int = 1000, hole_size: float = 0.1, labeled: bool = False, seed: int = 0):\n",
        "        super().__init__(num_groups=1, points_per_group=points_per_group, labeled=labeled)\n",
        "        self.data_type = \"SwissRoll\"\n",
        "        self.hole_size = hole_size\n",
        "        self.additional_description = f\"hole-size{hole_size:3.2f}\"\n",
        "        self.labels = None\n",
        "        self.seed = seed\n",
        "        self.rnd = np.random.RandomState(seed=seed)\n",
        "\n",
        "    def generate_data(self):\n",
        "        theta = 1.5 * np.pi * (1 + 2 * self.rnd.rand(self.points_per_group))\n",
        "        x = theta * np.cos(theta)\n",
        "        y = 21 * self.rnd.rand(self.points_per_group)\n",
        "        z = theta * np.sin(theta)\n",
        "\n",
        "        # Creating holes\n",
        "        mask = np.logical_or.reduce([(x - xi)**2 + (z - zi)**2 > self.hole_size**2 for xi, zi in zip(x, z)])\n",
        "        self.data = np.stack([x, y], axis=1)\n",
        "        self.labels = None\n",
        "\n",
        "    def plot_data(self, save_dir: Union[str, os.PathLike] = 'plots', additional_desc: str = '') -> None:\n",
        "        \"\"\" Pass additional description of this class when plotting (hole size) \"\"\"\n",
        "        super().plot_data(additional_desc=self.additional_description)\n",
        "\n",
        "    def save_data(self, save_dir: Union[str, os.PathLike] = 'datasets', file_name: str = None,\n",
        "                  additional_desc: str = ''):\n",
        "        \"\"\" Pass additional description of this class when saving the data (hole size) \"\"\"\n",
        "        super().save_data(additional_desc=self.additional_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "t7_td_T8xn7e",
        "outputId": "f06df9af-e0ca-43e4-fb15-6df236b453ca"
      },
      "outputs": [],
      "source": [
        "# Generate it\n",
        "dataset = SwissRollDataset(\n",
        "    points_per_group=2000, labeled=False, seed=1000)\n",
        "\n",
        "dataset.generate_data()\n",
        "# Plot it\n",
        "dataset.plot_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk2WkIXugCcj"
      },
      "source": [
        "### Mixture of Shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAixBXOCnTlk"
      },
      "outputs": [],
      "source": [
        "class MixtureOfShapesDataset(TwoDimensionalDataset):\n",
        "    def __init__(self, num_groups: int = 3, points_per_group: int = 100, labeled: bool = True, seed: int = 0):\n",
        "        super().__init__(num_groups, points_per_group, labeled)\n",
        "        self.data_type = \"MixtureOfShapes\"\n",
        "        self.seed = seed\n",
        "        self.rnd = np.random.RandomState(seed=seed)\n",
        "\n",
        "    def generate_data(self):\n",
        "        data = []\n",
        "        labels = [] if self.labeled else None\n",
        "        for i in range(self.num_groups):\n",
        "            shape = i % 3\n",
        "            if shape == 0:\n",
        "                # Circle\n",
        "                theta = np.linspace(0, 2 * np.pi, self.points_per_group)\n",
        "                x = np.cos(theta) + self.rnd.randn(self.points_per_group) * 0.1\n",
        "                y = np.sin(theta) + self.rnd.randn(self.points_per_group) * 0.1\n",
        "            elif shape == 1:\n",
        "                # Square corners\n",
        "                x = self.rnd.choice([-1, 1], size=self.points_per_group) + self.rnd.randn(self.points_per_group) * 0.1\n",
        "                y = self.rnd.choice([-1, 1], size=self.points_per_group) + self.rnd.randn(self.points_per_group) * 0.1\n",
        "            else:\n",
        "                # Lemniscate\n",
        "                theta = np.linspace(0, 2 * np.pi, self.points_per_group)\n",
        "                x = np.cos(theta) + self.rnd.randn(self.points_per_group) * 0.1\n",
        "                y = np.sin(theta) * np.abs(np.cos(theta)) + self.rnd.randn(self.points_per_group) * 0.1\n",
        "\n",
        "            shape_data = np.stack([x, y], axis=1)\n",
        "            data.append(shape_data)\n",
        "            if self.labeled:\n",
        "                labels.append(np.full(self.points_per_group, i))\n",
        "        self.data = np.vstack(data)\n",
        "        self.labels = np.concatenate(labels) if self.labeled else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WS5bn5z2n86D",
        "outputId": "f3fc6735-d24f-429b-9c2d-36d8212f3b6c"
      },
      "outputs": [],
      "source": [
        "# Generate it\n",
        "dataset = MixtureOfShapesDataset(\n",
        "    num_groups=3, points_per_group=1000, labeled=True)\n",
        "\n",
        "dataset.generate_data()\n",
        "# Plot it\n",
        "dataset.plot_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oILOFxogFsy"
      },
      "source": [
        "### Checkerboard with Irregular Borders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chXqrhwGoR8O"
      },
      "outputs": [],
      "source": [
        "class CheckerboardWithIrregularBordersDataset(TwoDimensionalDataset):\n",
        "    def __init__(self, num_groups: int = 2, grid_size: int = 8, points_per_group: int = 100, labeled: bool = True, seed: int = 0):\n",
        "        super().__init__(num_groups, points_per_group, labeled)\n",
        "        self.data_type = \"CheckerboardWithIrregularBorders\"\n",
        "        self.grid_size = grid_size\n",
        "        self.additional_description = f\"gridsize{grid_size:02d}\"\n",
        "        self.seed = seed\n",
        "        self.rnd = np.random.RandomState(seed=seed)\n",
        "\n",
        "    def generate_data(self):\n",
        "        data = []\n",
        "        labels = [] if self.labeled else None\n",
        "        for i in range(self.grid_size):\n",
        "            for j in range(self.grid_size):\n",
        "                x = self.rnd.rand(self.points_per_group) + i\n",
        "                y = self.rnd.rand(self.points_per_group) + j\n",
        "                if (i + j) % 2 == 0:\n",
        "                    x += np.sin(y * 3) * 0.2\n",
        "                block_data = np.stack([x, y], axis=1)\n",
        "                data.append(block_data)\n",
        "                if self.labeled:\n",
        "                    labels.append(np.full(self.points_per_group, (i + j) % self.num_groups))\n",
        "        self.data = np.vstack(data)\n",
        "        self.labels = np.concatenate(labels) if self.labeled else None\n",
        "\n",
        "    def plot_data(self, save_dir: Union[str, os.PathLike] = 'plots', additional_desc: str = '') -> None:\n",
        "        \"\"\" Pass additional description of this class when plotting (grid size of checkerboard) \"\"\"\n",
        "        super().plot_data(additional_desc=self.additional_description)\n",
        "\n",
        "    def save_data(self, save_dir: Union[str, os.PathLike] = 'datasets', file_name: str = None,\n",
        "                  additional_desc: str = ''):\n",
        "        \"\"\" Pass additional description of this class when saving the data (grid size of checkerboard) \"\"\"\n",
        "        super().save_data(additional_desc=self.additional_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ucHpIoaKobx0",
        "outputId": "26c7f254-4633-45b4-8bae-8dd3a918a036"
      },
      "outputs": [],
      "source": [
        "# Generate it\n",
        "dataset = CheckerboardWithIrregularBordersDataset(\n",
        "    num_groups=5, points_per_group=100, labeled=True, seed=1000)\n",
        "\n",
        "dataset.generate_data()\n",
        "# Plot it\n",
        "dataset.plot_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p-UZe_15J10"
      },
      "source": [
        "# Further Resources\n",
        "\n",
        "* [*GAN*](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), I. Goodfellow-et-al, 2014.\n",
        "    * [*Google's GAN Course*](https://developers.google.com/machine-learning/gan)\n",
        "    * [*Coursera's GAN Specialization*](https://www.coursera.org/specializations/generative-adversarial-networks-gans), S. Zhou, E. Zhou, E. Zelikman\n",
        "    * [*Deep Learning*](https://www.deeplearningbook.org), Goodfellow-et-al, 2016, MIT Press (specifically, Ch. 20, [*Deep Generative Models*](https://www.deeplearningbook.org/contents/generative_models.html), pp. 696-699)\n",
        "    * [*Improved Techniques for Training GANs*](https://arxiv.org/abs/1606.03498), T. Salimans-et-al, 2016\n",
        "    * [*NIPs 2016 Tutorial: GANs*](https://arxiv.org/abs/1701.00160), I. Goodfellow, NIPs 2016; check the [recorded video](https://youtu.be/HGYYEUSm-0Q) of the event as well\n",
        "    * [*GAN Lab*](https://poloclub.github.io/ganlab/), M. Kahng-et-al, 2018. 2D GAN that can be trained on the browser (using [TensorFlow.js](https://www.tensorflow.org/js/)).\n",
        "* [*DCGAN*](https://arxiv.org/abs/1511.06434), A. Radford-et-al, 2015.\n",
        "    * [*GAN Hacks*](https://github.com/soumith/ganhacks), S. Chintala-et-al, 2016.\n",
        "    * [*DCGAN Tensorflow tutorial*](https://www.tensorflow.org/tutorials/generative/dcgan)\n",
        "    * [*Deconvolution and Checkerboard Artifacts*](https://distill.pub/2016/deconv-checkerboard/), A.Odena-et-al, 2016 (particularly important for DCGAN and beyond).\n",
        "* [*WGAN*](https://arxiv.org/abs/1701.07875), M. Arjovsky-et-al, 2017.\n",
        "    * [*From GAN to WGAN*](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html), L. Weng, 2017.\n",
        "* [*StyleGAN*](https://arxiv.org/abs/1812.04948)\n",
        "    * [*Official `TensorFlow` implementation*](https://github.com/NVlabs/stylegan)\n",
        "    * https://thisvesseldoesnotexist.com\n",
        "    * [*Making Anime Faces with StyleGAN*](https://www.gwern.net/Faces), G. Branwen, 2019 (fun blog, but especially useful if you wish to start with SOTA GANs and their training specifics).\n",
        "* [*StyleGAN2*](https://arxiv.org/abs/1912.04958)\n",
        "    * [*Official `TensorFlow` implementation*](https://github.com/NVlabs/stylegan2)\n",
        "    * [*Colab notebook*](https://colab.research.google.com/drive/1ShgW6wohEFQtqs_znMna3dzrcVoABKIH)\n",
        "    * Works best if the dataset is aligned (e.g., for faces: eyes, mouth, nose in the same position...)\n",
        "    * https://www.thispersondoesnotexist.com/\n",
        "    * https://www.thiswaifudoesnotexist.net/\n",
        "* [*StyleGAN2-ADA*](https://arxiv.org/abs/2006.06676)\n",
        "    * [Official `PyTorch` implementation](https://github.com/NVlabs/stylegan2-ada-pytorch) (a bit faster to train vs. the `TensorFlow` one)\n",
        "    * Meant to be used for small datasets, e.g., on the order of 10^3\n",
        "* [*StyleGAN3*](https://arxiv.org/abs/2106.12423)\n",
        "    * [Official `PyTorch` implementation](https://github.com/NVlabs/stylegan3)\n",
        "    * Meant as a step towards generating animation, as well as removing the need to align the datasets (with the configs having translational and rotational equivariances)\n",
        "* [BigGAN](https://arxiv.org/abs/1809.11096)\n",
        "    * [*Colab notebook*](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb) (impossible to train your own from scratch, so only pretrained models exist)\n",
        "    * [*Art Breeder*](https://artbreeder.com/), J. Simon, 2018.\n",
        "* **Beyond...**\n",
        "    * [*Are GANs Created Equal? A Large-Scale Study*](https://arxiv.org/abs/1711.10337), M. Lucic-et-al, 2017.\n",
        "    * [*Generative Models*](https://github.com/wiseodd/generative-models), A. Kristiadi, 2018. A collection of many generative models (GANs and VAEs included), coded in `PyTorch` and `TensorFlow`.\n",
        "    * Make your own [<del>1D</del> *2D GAN*](https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/)! I digress with the author on the name of the project: while the function is indeed one-dimensional, the data you are feeding to the GAN is in fact two-dimensional (points in 2D space), hence my renaming.\n",
        "    * [*Open Questions About GANs*](https://distill.pub/2019/gan-open-problems/), A. Odena, 2019.\n",
        "    * [*A Review on GANs: Algorithms, Theory and Applications*](https://arxiv.org/abs/2001.06937), J. Gui-et-al, 2020. This is the paper you must read if you want a quick overview of the last ~6 years of GAN history."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2pkAzqKMba8"
      },
      "source": [
        "# Appendix A: On sampling from the latent space\n",
        "\n",
        "Once we have a trained Generator, we usually discard the Discriminator (unless, of course, if you have some interesting ideas like [Robbie Barrat](https://twitter.com/videodrome/status/1158419262463258624)). With it, we can then simply pass up some latent vectors and examine the generated output, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlnBWZ0PMerh",
        "outputId": "7002a0c3-432e-4d61-d0c0-6612ec56966d"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    # We generate 10 latent vectors and feed them to the generator\n",
        "    samples = generator(get_latents(N=10, latent_dim=latent_dim)).detach().cpu()\n",
        "\n",
        "# samples will be 10 one-dimensional vectors that should follow the distribution of\n",
        "# our data distribution:\n",
        "print(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYH4fBxwH6Y8"
      },
      "source": [
        "This is basically how you generate new data, which you are now confident that follows the desired distribution (should convergence has indeed occured).\n",
        "\n",
        "> As a side note, while `var.cpu().detach()` and `var.detach().cpu()` might look similar, [there is a specific difference between them](https://discuss.pytorch.org/t/should-it-really-be-necessary-to-do-var-detach-cpu-numpy/35489/8): if `var` requires gradient tracking, then the former will construct the autograd edge on `cpu`, and it will then be destroyed, whereas the latter doesn't do this. Since this is a relatively fast operation, not much is lost, but it's best to unnecessarily avoid wasting resources whenever possible.\n",
        "\n",
        "For example, to create those classical interpolation videos in the latent space, you typically generate two latent vectors and make an interpolation between them, generating an image at every step. Let's look at an example of this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "kpDEAzMYbKrE",
        "outputId": "824fccf8-6de7-4cde-e1ec-44226c7d7f6f"
      },
      "outputs": [],
      "source": [
        "YouTubeVideo('6E1_dgYlifc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZk9NMoDb7xh"
      },
      "source": [
        "I should note that, if your latent space is high-dimensional like, say $100$, then you **shouldn't** do a linear interpolation between two latent vectors. ***This is a common error that many do even today.*** This is due to the well-known [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality), of which we do not escape here. Indeed, for the $100$-dimensional latent space mentioned before, all of the mass of the Gaussian distribution would lay in an outer shell, not in the inner sphere!\n",
        "\n",
        "To better illustrate this, let's take an [hypersphere](https://en.wikipedia.org/wiki/Hypersphere) of radius $R$ in $n$ dimensions, which has an inner shell of radius $r$. In the following image, we show the cases for $n=2$ and $n=3$:\n",
        "\n",
        "![shell sphere](https://upload.wikimedia.org/wikipedia/commons/0/07/Kugelschale.svg \"shell sphere\")\n",
        "\n",
        "An equivalent formulation of this is that we have a hyper-orange and we're going to peel it. How much of the total volume are we going to lose when we throw away the peel?\n",
        "\n",
        "For $n=2$ we'll have to calculate areas, so let's see what percentage of the total area is comprised of *peel*:\n",
        "\n",
        "$$\\frac{\\pi R^2 - \\pi r^2}{\\pi R^2} = 1-(r/R)^2$$\n",
        "\n",
        "For $n=3$, we'll have volumes, so we do the same as above:\n",
        "\n",
        "$$\\frac{\\frac{4}{3}\\pi R^3 - \\frac{4}{3}\\pi r^3}{\\frac{4}{3}\\pi R^3} = 1-(r/R)^3$$\n",
        "\n",
        "For $n$ dimensions, this will be the [hyper volume](https://en.wikipedia.org/wiki/Volume_of_an_n-ball), so:\n",
        "\n",
        "$$ \\frac{V_n(R)-V_n(r)}{V_n(R)} = 1-\\frac{\\pi^{n/2}(r)^n/\\Gamma(1+n/2)}{\\pi^{n/2}(R)^n/\\Gamma(1+n/2)} = 1 - (r/R)^n $$\n",
        "\n",
        "with $\\Gamma$ being the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function) (think of it as a generalization of the factorial). Let's say the peel of our orange is somewhat thin, so that $r=0.95 R$, then we would get the following results:\n",
        "\n",
        "| Dimension | Ratio of peel to total volume |\n",
        "|---|---|\n",
        "| $n=2$ | 9.75% |\n",
        "| $n=3$ | 14.26% |\n",
        "| ... | ... |\n",
        "|$n=100$ | 99.41% |\n",
        "\n",
        "That is, in 100 dimensions, $99.41\\%$ of the hypersphere's volume lies in its outer shell, when $r=0.95R$. This is not an intuitive result, as in our everyday life, we don't lose the majority of the orange when we peel it! A similar argument can be made with [hypercubes](https://en.wikipedia.org/wiki/Hypercube), which is relevant when our latent vectors are drawn from the Uniform distribution. See a relevant discussion [here](https://datascience.stackexchange.com/a/27390).\n",
        "\n",
        "Coming back to GANs, almost all of the datapoints will lie in the outer shell of the hypersphere whenever we sample from a Normal or Uniform distribution. Reiterating, you should never do linear interpolation ([lerp](https://en.wikipedia.org/wiki/Linear_interpolation)) between two random latent vectors. Instead, you should do a spherical interpolation ([slerp](https://en.wikipedia.org/wiki/Slerp)) between them (hence Tip 3 in [S. Chintala's GAN Hacks](https://github.com/soumith/ganhacks)). Follow a much relevant discussion [here](https://github.com/soumith/dcgan.torch/issues/14#issuecomment-199171316), as well as some starter code in how to do this spherical interpolation in `Python`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY6IFtiMC7K5"
      },
      "source": [
        "# Appendix B: Why is it so hard to train a GAN?\n",
        "\n",
        "As you have seen, the process of training a GAN can be quite straightforward: get a dataset, define your generator and discriminator, set up your training loop *et voila*. Were it so easy. Remember that both networks are playing a game, and they must thus reach a [Nash equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium).\n",
        "\n",
        "This translates to a myriad of problems, perhaps some of the most famous being **mode collapse** and **convergence failure**. Let us discuss these two briefly:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArTOAQTELNZD"
      },
      "source": [
        "### Mode Collapse\n",
        "\n",
        "**Mode collapse** refers to the phenomena when $G$ generates one or a few different samples or modes, no matter the input $z$. How does this happen?\n",
        "\n",
        "In as few words as possible, what happens is that since we keep our Discriminator $D$ fixed when training the Generator $G$, $G$ thinks there exists a single point $x^{*}=G(z)=\\arg\\max_x D(x)$ that is the optimal to generate, regardless of the input $z$. After all, our objective function doesn't have a way to tell $G$ to *diversify* its output.\n",
        "\n",
        "Do note that even SOTA GANs can suffer from mode collapse, even after applying all the possible tricks in the book, like changes in the loss function, more complicated architectures, etc. For example, take a look at an interpolation video of collapsed StyleGAN2 that I've recently trained with circa 12k images of the details of [huipils](https://en.wikipedia.org/wiki/Huipil) from Guatemala (my home country) and Mexico:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "w0yfHgdYLVS3",
        "outputId": "1f740dc2-bfd1-40ac-9353-6460882b282d"
      },
      "outputs": [],
      "source": [
        "YouTubeVideo('5Iy60yEwYiw')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkMAUOBY7I1p"
      },
      "source": [
        "Although it is tempting to say that perhaps there isn't enough training data, the next video shows the same model trained for far longer (almost twice as long), with minor signs of mode collapse (I hope you can identify them):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "pB8UJr9G7UfE",
        "outputId": "160c3884-17bf-4421-913e-02c262ae7d95"
      },
      "outputs": [],
      "source": [
        "YouTubeVideo('t9fv4AAt6lw')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snd__xmMnlvb"
      },
      "source": [
        "If you have **total collapse**, that is, for any input, you obtain the *same* output, then you must restart your training. This is because, while $D$ will be able to identify this mode as the fake one and this be reflected in the signal it transmits to $G$ for updating its parameters, this signal will be the same for all latent vectors in the batch. As such, they will *all* move in the same direction, producing a different output, but the same for all elements in the batch, so we're still at total collapse.\n",
        "\n",
        "Perhaps the best way to guarantee mode collapse is by not having a complex enough latent space. This will be hard to achieve in this notebook due to the relatively easy dataset we are using, but you can get this in the [DCGAN tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). In it, the authors set the latent dimension to `nz=100`, so if you set `nz=1` for example, you are more than likely to get mode collapse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYasAxZyCQ3N"
      },
      "source": [
        "### Convergence Failure\n",
        "\n",
        "**Convergence failure** is the most common failure pitfall in training a GAN. In it, $G$ will simply produce garbage output that is easily recognized by $D$, no matter how much you train your network. If your learning rate is too high, or perhaps the architecture of both $G$ and $D$ is too simple for the data at hand, you will see instances of this failure mode. Therefore, a careful selection of the hyperparameters is warranted, as in any deep learning training loop.\n",
        "\n",
        "It is not hard to imagine what happens when a GAN fails to converge. The following image shows such a case, even after training the GAN for $450$ epochs:\n",
        "\n",
        "![Convergence failure](https://machinelearningmastery.com/wp-content/uploads/2019/07/Sample-of-100-Generated-Images-of-a-Handwritten-Number-8-at-Epoch-450-from-a-GAN-that-has-a-Convergence-Failure-via-Combined-Updates-to-the-Discriminator.png \"Convergence failure\")\n",
        "[Image Source](https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAbD-XCKOGYa"
      },
      "source": [
        "For a more detailed summary of these caveats, see Samuel Barnett's dissertation [*Convergence Problems with GANs*](https://arxiv.org/abs/1806.11382)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvcjS0xj7sVE"
      },
      "source": [
        "# Appendix C: Evaluating a GAN\n",
        "\n",
        "In this notebook, we have been plotting the distribution (or at least, a fitted KDE) of the generated data to aid in our understanding whether or not the generated distribution has converged to the real data distribution. While certainly useful for this low dimension sample, it is extremely unreliable to do this in higher dimensions (i.e., images), so don't try this method when evaluating images generated by a GAN!\n",
        "\n",
        "We must instead use other methods of evaluating whether or not a GAN is *correctly* generating images. Now, this is a tricky situation, as image generation can be simply too subjective, but there are some metrics that have been proposed and are useful to benchmark the image generation capabilities of the current SOTA GANS.\n",
        "\n",
        "We will mention two of the most used ones, Inception Score and Frchet Inception Distance, but note that these metrics aren't set on stone. We won't delve too deep into their details, as they are plenty, so instead I redirect you to, e.g., [Neal Jean's blog](https://nealjean.com/ml/frechet-inception-distance/) if you wish a more detailed explanation, or to the linked papers in each title."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWmbVsF98i8j"
      },
      "source": [
        "## [Inception Score](https://arxiv.org/abs/1606.03498)\n",
        "\n",
        "The **Inception Score** (IS) was developed as a way to independently judge the quality of generated images by a GAN. It is a real number that was meant to replace human evaluators, as it was done in some of the first papers on the subject.\n",
        "\n",
        "The IS is meant to measure two things simultaneously:\n",
        "\n",
        "* That the generated images are **diverse** or have variety\n",
        "* That each generated image has a **clear object** or that it's not blurry\n",
        "\n",
        "As such, the higher the IS, the better, with the lowest possible value being $1.00$ and the highest being the number of classes that the classification model has. Take a look, for example, at the [SOTA IS on the CIFAR-10 dataset](https://paperswithcode.com/sota/image-generation-on-cifar-10): the highest possible value is thus $10.0$ and as of now the SOTA is [$10.020$](https://arxiv.org/abs/2006.06676). A final point is that the IS should be calculated usinig a high number of generated images such as $50,000$ as noted by [Salimans-et-al, 2016](https://arxiv.org/abs/1606.03498).\n",
        "\n",
        "However, the IS has a downfall: if used as a parameter to optimize, rather as a rough guide for image generation, then we obtain adversarial examples rather than meaningful images. This was shown by [Barratt & Sharma, 2018](https://arxiv.org/abs/1801.01973), where they achieve a high IS but nonsensical outputs, from a purely aesthetic point of view. See the Figures 1 and 2 of their paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y393NBRf8lIT"
      },
      "source": [
        "## [Frchet Inception Distance](https://arxiv.org/abs/1706.08500)\n",
        "\n",
        "Another caveat from the IS was that the generated images aren't compared against real images, so there is no way of telling whether the GAN is actually generating images on the target domain. As such, the **Frchet Inception Distance** (FID) was born.\n",
        "\n",
        "The FID seeks to measure the statistics between the generated and real images, with these being calculated via the activations of the [Inception v3](https://arxiv.org/abs/1512.00567) model and using the [Frchet distance](https://en.wikipedia.org/wiki/Fr%C3%A9chet_distance).\n",
        "\n",
        "Hence, the lower the FID, the better, which will correspond to more similar generated and real images. For example, we can see a graph of the [SOTA FID on the FFHQ dataset](https://paperswithcode.com/sota/image-generation-on-ffhq), where the current lowest FID is now [$2.840$](https://arxiv.org/abs/1912.04958v2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trRIaPDJqJl8"
      },
      "source": [
        "For practice, you could try to implement both of these metrics in your trials for Exercise 1 and 2 and let these guide on how well your changes are. You can skip using the pre-trained models of course, and perhaps only use the calculated mean, standard deviation, covariance (variance) for this one-dimensional case. These metrics are beyond the scope of this exercise, so we won't be delving too much in this area."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "a7wzQ1DsYKEi",
        "roCAMaomPoBF",
        "_-uR-K8Npc-P",
        "sWyH3vxUM3Hp",
        "js1h0_a0P0i4",
        "yeHyqzU6QAWO",
        "aKXpR-QXpFCF",
        "TZMdqQfIMPVE",
        "_kpolv4zficY",
        "B9s15wv1R6E4",
        "TeyYW1PPR9px",
        "2W4DL76GcaTp",
        "eZQn5Yp2E16g",
        "4JuhNcesqZYw",
        "Rw6Zc0Se-lCJ",
        "T2pkAzqKMba8",
        "uY6IFtiMC7K5",
        "ArTOAQTELNZD",
        "IYasAxZyCQ3N",
        "fvcjS0xj7sVE",
        "Y393NBRf8lIT"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
